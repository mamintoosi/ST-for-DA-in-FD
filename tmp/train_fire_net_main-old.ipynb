{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_fire_net_main.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP1sB+3mu/Ajm+UZloH8K2N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"B4yxkb0QLPFm"},"source":["# انتقال سبک با شبکه‌ی مولد رقابتی برای افزایش داده‌های آموزشی شبکه‌های پیچشی در شناسایی شعله‌ی آتش\n","\n","M. Amintoosi, m.amintoosi@gmail.com"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_UtaKjGbDQw1","executionInfo":{"status":"ok","timestamp":1622815255763,"user_tz":-270,"elapsed":7096,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"39190aa5-c2f1-44db-94b7-147dd6c098d3"},"source":["!git clone https://github.com/mamintoosi-papers-codes/ImageAI.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'ImageAI'...\n","remote: Enumerating objects: 2299, done.\u001b[K\n","remote: Counting objects: 100% (136/136), done.\u001b[K\n","remote: Compressing objects: 100% (107/107), done.\u001b[K\n","remote: Total 2299 (delta 48), reused 73 (delta 25), pack-reused 2163\u001b[K\n","Receiving objects: 100% (2299/2299), 60.84 MiB | 19.92 MiB/s, done.\n","Resolving deltas: 100% (1135/1135), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2xnXw7rD0do","executionInfo":{"status":"ok","timestamp":1622815270827,"user_tz":-270,"elapsed":12539,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"4378c2ae-69f0-439e-ac27-1b4832698c3f"},"source":["%cd ImageAI\n","!wget https://pjreddie.com/media/files/yolov3.weights"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/ImageAI\n","--2021-06-04 14:00:56--  https://pjreddie.com/media/files/yolov3.weights\n","Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n","Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 248007048 (237M) [application/octet-stream]\n","Saving to: ‘yolov3.weights’\n","\n","yolov3.weights      100%[===================>] 236.52M  22.5MB/s    in 11s     \n","\n","2021-06-04 14:01:09 (21.4 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8dMA5tRoTIeu","executionInfo":{"status":"ok","timestamp":1622815308021,"user_tz":-270,"elapsed":11402,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"b1e015f5-07d7-498f-dd3e-b1d0759c41d7"},"source":["from utils.convert_yolo3_to_keras  import make_yolov3_model,WeightReader\n","# define the model\n","model = make_yolov3_model()\n","# load the model weights\n","weight_reader = WeightReader('yolov3.weights')\n","# set the model weights into the model\n","weight_reader.load_weights(model)\n","# save the model to file\n","model.save('pretrained-yolov3.h5')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["loading weights of convolution #0\n","loading weights of convolution #1\n","loading weights of convolution #2\n","loading weights of convolution #3\n","no convolution #4\n","loading weights of convolution #5\n","loading weights of convolution #6\n","loading weights of convolution #7\n","no convolution #8\n","loading weights of convolution #9\n","loading weights of convolution #10\n","no convolution #11\n","loading weights of convolution #12\n","loading weights of convolution #13\n","loading weights of convolution #14\n","no convolution #15\n","loading weights of convolution #16\n","loading weights of convolution #17\n","no convolution #18\n","loading weights of convolution #19\n","loading weights of convolution #20\n","no convolution #21\n","loading weights of convolution #22\n","loading weights of convolution #23\n","no convolution #24\n","loading weights of convolution #25\n","loading weights of convolution #26\n","no convolution #27\n","loading weights of convolution #28\n","loading weights of convolution #29\n","no convolution #30\n","loading weights of convolution #31\n","loading weights of convolution #32\n","no convolution #33\n","loading weights of convolution #34\n","loading weights of convolution #35\n","no convolution #36\n","loading weights of convolution #37\n","loading weights of convolution #38\n","loading weights of convolution #39\n","no convolution #40\n","loading weights of convolution #41\n","loading weights of convolution #42\n","no convolution #43\n","loading weights of convolution #44\n","loading weights of convolution #45\n","no convolution #46\n","loading weights of convolution #47\n","loading weights of convolution #48\n","no convolution #49\n","loading weights of convolution #50\n","loading weights of convolution #51\n","no convolution #52\n","loading weights of convolution #53\n","loading weights of convolution #54\n","no convolution #55\n","loading weights of convolution #56\n","loading weights of convolution #57\n","no convolution #58\n","loading weights of convolution #59\n","loading weights of convolution #60\n","no convolution #61\n","loading weights of convolution #62\n","loading weights of convolution #63\n","loading weights of convolution #64\n","no convolution #65\n","loading weights of convolution #66\n","loading weights of convolution #67\n","no convolution #68\n","loading weights of convolution #69\n","loading weights of convolution #70\n","no convolution #71\n","loading weights of convolution #72\n","loading weights of convolution #73\n","no convolution #74\n","loading weights of convolution #75\n","loading weights of convolution #76\n","loading weights of convolution #77\n","loading weights of convolution #78\n","loading weights of convolution #79\n","loading weights of convolution #80\n","loading weights of convolution #81\n","no convolution #82\n","no convolution #83\n","loading weights of convolution #84\n","no convolution #85\n","no convolution #86\n","loading weights of convolution #87\n","loading weights of convolution #88\n","loading weights of convolution #89\n","loading weights of convolution #90\n","loading weights of convolution #91\n","loading weights of convolution #92\n","loading weights of convolution #93\n","no convolution #94\n","no convolution #95\n","loading weights of convolution #96\n","no convolution #97\n","no convolution #98\n","loading weights of convolution #99\n","loading weights of convolution #100\n","loading weights of convolution #101\n","loading weights of convolution #102\n","loading weights of convolution #103\n","loading weights of convolution #104\n","loading weights of convolution #105\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pfX616JDUKn2","executionInfo":{"status":"ok","timestamp":1622815312941,"user_tz":-270,"elapsed":553,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"fac1f19a-1c3e-43b2-b83e-70b8f5299db4"},"source":["# !ls -s\n","!rm -r datasets/"],"execution_count":5,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'datasets/': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7xoHtErDQ5V","executionInfo":{"status":"ok","timestamp":1622815321791,"user_tz":-270,"elapsed":3385,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"b1f4d484-191d-4cf3-f197-6f985c114188"},"source":["!git clone https://github.com/mamintoosi/datasets.git"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Cloning into 'datasets'...\n","remote: Enumerating objects: 1721, done.\u001b[K\n","remote: Counting objects: 100% (1721/1721), done.\u001b[K\n","remote: Compressing objects: 100% (1212/1212), done.\u001b[K\n","remote: Total 1721 (delta 508), reused 1714 (delta 504), pack-reused 0\u001b[K\n","Receiving objects: 100% (1721/1721), 23.71 MiB | 25.32 MiB/s, done.\n","Resolving deltas: 100% (508/508), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D8MQrPGCafnx"},"source":["## آموزش و اجرا بر روی نمونه‌های اصلی، مدل پایه"]},{"cell_type":"code","metadata":{"id":"jjyQlKDShhma","executionInfo":{"status":"ok","timestamp":1622815967950,"user_tz":-270,"elapsed":543,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}}},"source":["# آموزش مدل بر روی تصاویر آموزشی\n","ds_name = \"fire-dataset-outdoor\""],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pbS_Dv9uD5NJ","executionInfo":{"status":"ok","timestamp":1621740462999,"user_tz":-270,"elapsed":4566997,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"61dabb6f-1de3-4605-ecf5-1824705d457b"},"source":["# آموزش مدل حدود یک ساعت و ربع طول خواهد کشید. \n","# درصورت تمایل می‌توانید این بخش را اجرا نکرده و در سلول های بعدی از مدل آموزش دیده‌ی پیشین استفاده کنید\n","from imageai.Detection.Custom import DetectionModelTrainer\n","\n","trainer = DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=\"datasets/\"+ds_name)\n","trainer.setTrainConfig(object_names_array=[\"fire\"], batch_size=8, num_experiments=20, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n","# In the above,when training for detecting multiple objects,\n","#set object_names_array=[\"object1\", \"object2\", \"object3\",...\"objectz\"]\n","trainer.trainModel()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Generating anchor boxes for training images and annotation...\n","Average IOU for 9 anchors: 0.79\n","Anchor Boxes generated.\n","Detection configuration saved in  datasets/fire-dataset-outdoor/json/detection_config.json\n","Evaluating over 60 samples taken from datasets/fire-dataset-outdoor/validation\n","Training over 305 samples  given at datasets/fire-dataset-outdoor/train\n","Training on: \t['fire']\n","Training with Batch Size:  8\n","Number of Training Samples:  305\n","Number of Validation Samples:  60\n","Number of Experiments:  20\n","Training with transfer learning from pretrained Model\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n","  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n","Epoch 1/20\n","312/312 [==============================] - 283s 795ms/step - loss: 100.1286 - yolo_layer_loss: 15.5578 - yolo_layer_1_loss: 23.2573 - yolo_layer_2_loss: 49.7491 - val_loss: 50.1260 - val_yolo_layer_loss: 16.2320 - val_yolo_layer_1_loss: 9.3063 - val_yolo_layer_2_loss: 13.3046\n","Epoch 2/20\n","312/312 [==============================] - 244s 780ms/step - loss: 36.2965 - yolo_layer_loss: 6.7272 - yolo_layer_1_loss: 7.5814 - yolo_layer_2_loss: 10.8762 - val_loss: 35.9077 - val_yolo_layer_loss: 8.3487 - val_yolo_layer_1_loss: 7.0091 - val_yolo_layer_2_loss: 9.9091\n","Epoch 3/20\n","312/312 [==============================] - 215s 689ms/step - loss: 33.1031 - yolo_layer_loss: 5.5509 - yolo_layer_1_loss: 6.4316 - yolo_layer_2_loss: 10.6903 - val_loss: 33.0262 - val_yolo_layer_loss: 6.5749 - val_yolo_layer_1_loss: 6.2891 - val_yolo_layer_2_loss: 10.4187\n","Epoch 4/20\n","312/312 [==============================] - 217s 693ms/step - loss: 30.9674 - yolo_layer_loss: 5.0154 - yolo_layer_1_loss: 6.3636 - yolo_layer_2_loss: 10.0016 - val_loss: 31.9956 - val_yolo_layer_loss: 6.0114 - val_yolo_layer_1_loss: 6.6169 - val_yolo_layer_2_loss: 10.1998\n","Epoch 5/20\n","312/312 [==============================] - 218s 697ms/step - loss: 29.3865 - yolo_layer_loss: 4.7432 - yolo_layer_1_loss: 6.0240 - yolo_layer_2_loss: 9.6298 - val_loss: 31.5416 - val_yolo_layer_loss: 7.0718 - val_yolo_layer_1_loss: 5.7789 - val_yolo_layer_2_loss: 10.1871\n","Epoch 6/20\n","312/312 [==============================] - 241s 770ms/step - loss: 28.5674 - yolo_layer_loss: 4.6828 - yolo_layer_1_loss: 6.2995 - yolo_layer_2_loss: 9.1885 - val_loss: 29.3758 - val_yolo_layer_loss: 5.7060 - val_yolo_layer_1_loss: 5.3595 - val_yolo_layer_2_loss: 10.1776\n","Epoch 7/20\n","312/312 [==============================] - 222s 711ms/step - loss: 27.5952 - yolo_layer_loss: 4.4498 - yolo_layer_1_loss: 6.0049 - yolo_layer_2_loss: 9.0951 - val_loss: 29.3980 - val_yolo_layer_loss: 5.8230 - val_yolo_layer_1_loss: 6.1592 - val_yolo_layer_2_loss: 9.6268\n","Epoch 8/20\n","312/312 [==============================] - 227s 728ms/step - loss: 27.0966 - yolo_layer_loss: 4.4487 - yolo_layer_1_loss: 6.0071 - yolo_layer_2_loss: 8.9315 - val_loss: 28.7793 - val_yolo_layer_loss: 4.8055 - val_yolo_layer_1_loss: 5.7317 - val_yolo_layer_2_loss: 10.7528\n","Epoch 9/20\n","312/312 [==============================] - 223s 714ms/step - loss: 26.0895 - yolo_layer_loss: 3.9019 - yolo_layer_1_loss: 5.5187 - yolo_layer_2_loss: 9.2515 - val_loss: 27.7540 - val_yolo_layer_loss: 5.2868 - val_yolo_layer_1_loss: 5.7554 - val_yolo_layer_2_loss: 9.4985\n","Epoch 10/20\n","312/312 [==============================] - 212s 677ms/step - loss: 25.7971 - yolo_layer_loss: 4.0668 - yolo_layer_1_loss: 5.4865 - yolo_layer_2_loss: 9.0850 - val_loss: 26.5363 - val_yolo_layer_loss: 4.8409 - val_yolo_layer_1_loss: 5.5367 - val_yolo_layer_2_loss: 9.1677\n","Epoch 11/20\n","312/312 [==============================] - ETA: 0s - loss: 26.0460 - yolo_layer_loss: 4.6897 - yolo_layer_1_loss: 5.7177 - yolo_layer_2_loss: 8.6947Epoch 12/20\n","312/312 [==============================] - 223s 712ms/step - loss: 24.8516 - yolo_layer_loss: 4.3158 - yolo_layer_1_loss: 5.4233 - yolo_layer_2_loss: 8.3633 - val_loss: 25.5368 - val_yolo_layer_loss: 4.6288 - val_yolo_layer_1_loss: 5.0512 - val_yolo_layer_2_loss: 9.2497\n","Epoch 13/20\n","312/312 [==============================] - 218s 697ms/step - loss: 24.6737 - yolo_layer_loss: 4.0195 - yolo_layer_1_loss: 5.6029 - yolo_layer_2_loss: 8.4847 - val_loss: 25.7667 - val_yolo_layer_loss: 4.5392 - val_yolo_layer_1_loss: 5.0279 - val_yolo_layer_2_loss: 9.7541\n","Epoch 14/20\n","312/312 [==============================] - 236s 756ms/step - loss: 24.5896 - yolo_layer_loss: 4.0443 - yolo_layer_1_loss: 5.7308 - yolo_layer_2_loss: 8.4083 - val_loss: 26.7112 - val_yolo_layer_loss: 6.0192 - val_yolo_layer_1_loss: 5.7631 - val_yolo_layer_2_loss: 8.6322\n","Epoch 15/20\n","312/312 [==============================] - 224s 718ms/step - loss: 23.4339 - yolo_layer_loss: 3.7749 - yolo_layer_1_loss: 5.4391 - yolo_layer_2_loss: 7.9560 - val_loss: 25.6493 - val_yolo_layer_loss: 4.5456 - val_yolo_layer_1_loss: 5.2214 - val_yolo_layer_2_loss: 9.7172\n","Epoch 16/20\n","312/312 [==============================] - 201s 644ms/step - loss: 22.9827 - yolo_layer_loss: 3.2513 - yolo_layer_1_loss: 5.0675 - yolo_layer_2_loss: 8.5317 - val_loss: 25.2904 - val_yolo_layer_loss: 4.3991 - val_yolo_layer_1_loss: 4.9443 - val_yolo_layer_2_loss: 9.9109\n","Epoch 17/20\n","312/312 [==============================] - 208s 665ms/step - loss: 22.8075 - yolo_layer_loss: 3.5333 - yolo_layer_1_loss: 4.9360 - yolo_layer_2_loss: 8.3287 - val_loss: 25.9259 - val_yolo_layer_loss: 4.8157 - val_yolo_layer_1_loss: 5.6276 - val_yolo_layer_2_loss: 9.5661\n","Epoch 18/20\n","312/312 [==============================] - 232s 742ms/step - loss: 23.1546 - yolo_layer_loss: 3.9511 - yolo_layer_1_loss: 5.3259 - yolo_layer_2_loss: 7.9874 - val_loss: 25.8957 - val_yolo_layer_loss: 5.6043 - val_yolo_layer_1_loss: 5.3390 - val_yolo_layer_2_loss: 9.1372\n","Epoch 19/20\n","312/312 [==============================] - 228s 730ms/step - loss: 22.9033 - yolo_layer_loss: 3.9755 - yolo_layer_1_loss: 5.3309 - yolo_layer_2_loss: 7.8055 - val_loss: 25.7185 - val_yolo_layer_loss: 4.9988 - val_yolo_layer_1_loss: 5.6095 - val_yolo_layer_2_loss: 9.3878\n","Epoch 20/20\n","312/312 [==============================] - 222s 712ms/step - loss: 21.9792 - yolo_layer_loss: 3.3006 - yolo_layer_1_loss: 5.0743 - yolo_layer_2_loss: 7.9031 - val_loss: 25.2301 - val_yolo_layer_loss: 4.8955 - val_yolo_layer_1_loss: 5.5943 - val_yolo_layer_2_loss: 9.1034\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjO4sfgehuaS","executionInfo":{"status":"ok","timestamp":1621740725167,"user_tz":-270,"elapsed":1762,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"d271b090-6fde-4c75-f27f-5dd2f5a1a8a9"},"source":["# print(\"datasets/\"+ds_name)\n","!ls ./datasets/fire-dataset-outdoor/models"],"execution_count":null,"outputs":[{"output_type":"stream","text":["detection_model-ex-001--loss-0060.636.h5\n","detection_model-ex-002--loss-0035.433.h5\n","detection_model-ex-003--loss-0032.327.h5\n","detection_model-ex-004--loss-0030.517.h5\n","detection_model-ex-005--loss-0029.137.h5\n","detection_model-ex-006--loss-0028.696.h5\n","detection_model-ex-007--loss-0027.445.h5\n","detection_model-ex-008--loss-0026.860.h5\n","detection_model-ex-009--loss-0026.195.h5\n","detection_model-ex-010--loss-0025.546.h5\n","detection_model-ex-012--loss-0024.539.h5\n","detection_model-ex-014--loss-0024.312.h5\n","detection_model-ex-015--loss-0023.752.h5\n","detection_model-ex-016--loss-0022.701.h5\n","detection_model-ex-017--loss-0022.653.h5\n","detection_model-ex-019--loss-0022.593.h5\n","detection_model-ex-020--loss-0022.157.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1zxu5GE9RHiM","executionInfo":{"status":"ok","timestamp":1622815470705,"user_tz":-270,"elapsed":1574,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}}},"source":["# پس از آموزش باید نام بهترین مدل (آخرین مدل ذخیره شده در لیست بالا) در سلول پایینی به جای نام مدل قرار داده شود.\n","# در صورتی که مایلید از مدل از پیش آموزش دیده استفاده کنید، به جای آموزش بالا، دستورات زیر را فعال و اجرا کنید تا مدل قبلی دانلود شود\n","\n","# !gdown https://drive.google.com/uc?id=1-3lLR-BVw6jGEzF4N6z0VokaPmvWVez7\n","# !mkdir ./datasets/fire-dataset-outdoor/models\n","# !mv detection_model-ex-020--loss-0022.157.h5 ./datasets/fire-dataset-outdoor/models/\n","# !gdown https://drive.google.com/uc?id=1-DIFWX0upTPM_tSN3CJ31pEeqGqkKiMr\n","# !mkdir ./datasets/fire-dataset-outdoor/json\n","# !mv detection_config.json ./datasets/fire-dataset-outdoor/json/"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QNFSMl7WGYQ","executionInfo":{"status":"ok","timestamp":1622815989349,"user_tz":-270,"elapsed":10553,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"4e0afd1b-f986-42ab-9643-7cca8fc77e0c"},"source":["%%time\n","from imageai.Detection.Custom import DetectionModelTrainer\n","\n","trainer = DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=\"./datasets/\"+ds_name)\n","metrics = trainer.evaluateModel(model_path=\"./datasets/\"+ds_name+\"/models/detection_model-ex-020--loss-0022.157.h5\",\\\n","                                json_path=\"./datasets/\"+ds_name+\"/json/detection_config.json\",\\\n","                                iou_threshold=0.2,\\\n","                                object_threshold=0.3, nms_threshold=0.3)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Starting Model evaluation....\n","Evaluating over 60 samples taken from ./datasets/fire-dataset-outdoor/validation\n","Training over 305 samples  given at ./datasets/fire-dataset-outdoor/train\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","Model File:  ./datasets/fire-dataset-outdoor/models/detection_model-ex-020--loss-0022.157.h5 \n","\n","Evaluation samples:  60\n","Using IoU:  0.2\n","Using Object Threshold:  0.3\n","Using Non-Maximum Suppression:  0.3\n","fire: 0.7140\n","mAP: 0.7140\n","===============================\n","CPU times: user 9.86 s, sys: 240 ms, total: 10.1 s\n","Wall time: 9.99 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3oK9Dq5aHcy","executionInfo":{"status":"ok","timestamp":1622816711467,"user_tz":-270,"elapsed":13004,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"b0e76c37-cdb0-405a-e0c8-031939f4d7f1"},"source":["# درصورتی که از مدل از قبل آموزش دیده استفاده کرده باشید،‌با دستورات زیر می‌توان مدل را روی تصاویر موجود در پوشه \n","# path\n","# اجرا کرد. \n","# اگر از مدل آموزش دیده خود استفاده می‌کنید، نام مدل را باید اصلاح کنید.\n","from PIL import Image\n","import os, sys\n","from imageai.Detection.Custom import CustomObjectDetection\n","\n","ds_name = \"fire-dataset-outdoor\"\n","\n","path = \"./datasets/\"+ds_name+\"/validation/images/\"\n","dirs = os.listdir( path )\n","# print(dirs)\n","out_path = \"./results_\"+ds_name\n","os.mkdir(out_path)\n","\n","detector = CustomObjectDetection()\n","detector.setModelTypeAsYOLOv3()\n","detector.setModelPath(\"./datasets/\"+ds_name+\"/models/detection_model-ex-020--loss-0022.157.h5\")\n","detector.setJsonPath(\"./datasets/\"+ds_name+\"/json/detection_config.json\")\n","detector.loadModel()\n","\n","for item in dirs:\n","    if os.path.isfile(path+item):\n","        in_im = path+item\n","        out_im = out_path+\"/\"+item\n","        detections = detector.detectObjectsFromImage(input_image=in_im, output_image_path=out_im)\n","\n","# بعد از اجرای کد بالا، تصاویر در پوشه\n","# results_fire-dataset-outdoor\n","# قرار داده می‌شوند که می‌توان دانلود نمود"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3704: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n","  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"QN4lEmbqaIdD"},"source":["## D2N آموزش و اجرا بر روی نمونه‌های اضافه شده با انتقال سبک عصبی، مدل \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"MuBN0ownBPPC","executionInfo":{"status":"ok","timestamp":1622815844461,"user_tz":-270,"elapsed":808,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"bf6780b1-7a75-4e24-dd9c-a328ccc7960c"},"source":["# آموزش مدل بر روی تصاویر آموزشی + تصاویر روز به شب شده با انتقال سبک\n","ds_name = \"fire-dataset-outdoor-d2n\"\n","ds_name"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'fire-dataset-outdoor-d2n'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSB_0h5wBSk5","executionInfo":{"status":"ok","timestamp":1621649090097,"user_tz":-270,"elapsed":5478961,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"def622ad-4af4-4cf2-a49c-2863e2fe7908"},"source":["# آموزش مدل حدود یک ساعت و نیم طول خواهد کشید. \n","# درصورت تمایل می‌توانید این بخش را اجرا نکرده و در سلول های بعدی از مدل آموزش دیده‌ی پیشین استفاده کنید\n","from imageai.Detection.Custom import DetectionModelTrainer\n","\n","trainer = DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=\"datasets/\"+ds_name)\n","trainer.setTrainConfig(object_names_array=[\"fire\"], batch_size=8, num_experiments=20, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n","trainer.trainModel()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Generating anchor boxes for training images and annotation...\n","Average IOU for 9 anchors: 0.78\n","Anchor Boxes generated.\n","Detection configuration saved in  datasets/fire-dataset-outdoor-d2n/json/detection_config.json\n","Evaluating over 60 samples taken from datasets/fire-dataset-outdoor-d2n/validation\n","Training over 390 samples  given at datasets/fire-dataset-outdoor-d2n/train\n","Training on: \t['fire']\n","Training with Batch Size:  8\n","Number of Training Samples:  390\n","Number of Validation Samples:  60\n","Number of Experiments:  20\n","Training with transfer learning from pretrained Model\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n","  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n","Epoch 1/20\n","392/392 [==============================] - 318s 722ms/step - loss: 102.2295 - yolo_layer_loss: 15.9157 - yolo_layer_1_loss: 21.3793 - yolo_layer_2_loss: 53.3766 - val_loss: 47.0552 - val_yolo_layer_loss: 18.0321 - val_yolo_layer_1_loss: 3.9191 - val_yolo_layer_2_loss: 13.7748\n","Epoch 2/20\n","392/392 [==============================] - 273s 696ms/step - loss: 34.6074 - yolo_layer_loss: 6.8308 - yolo_layer_1_loss: 4.1471 - yolo_layer_2_loss: 12.6610 - val_loss: 33.2157 - val_yolo_layer_loss: 7.3640 - val_yolo_layer_1_loss: 3.8958 - val_yolo_layer_2_loss: 12.0646\n","Epoch 3/20\n","392/392 [==============================] - 282s 720ms/step - loss: 30.2834 - yolo_layer_loss: 5.5509 - yolo_layer_1_loss: 3.4868 - yolo_layer_2_loss: 11.6147 - val_loss: 31.3753 - val_yolo_layer_loss: 6.5889 - val_yolo_layer_1_loss: 2.9595 - val_yolo_layer_2_loss: 12.9059\n","Epoch 4/20\n","392/392 [==============================] - 274s 698ms/step - loss: 28.6144 - yolo_layer_loss: 5.2829 - yolo_layer_1_loss: 3.8925 - yolo_layer_2_loss: 10.7201 - val_loss: 29.3486 - val_yolo_layer_loss: 5.8689 - val_yolo_layer_1_loss: 3.6477 - val_yolo_layer_2_loss: 11.6754\n","Epoch 5/20\n","392/392 [==============================] - 277s 705ms/step - loss: 27.4591 - yolo_layer_loss: 5.2186 - yolo_layer_1_loss: 3.5761 - yolo_layer_2_loss: 10.6844 - val_loss: 33.0963 - val_yolo_layer_loss: 10.6021 - val_yolo_layer_1_loss: 3.3381 - val_yolo_layer_2_loss: 11.6373\n","Epoch 6/20\n","392/392 [==============================] - 276s 703ms/step - loss: 26.9995 - yolo_layer_loss: 5.0775 - yolo_layer_1_loss: 4.2250 - yolo_layer_2_loss: 10.3156 - val_loss: 28.2638 - val_yolo_layer_loss: 6.8032 - val_yolo_layer_1_loss: 3.3821 - val_yolo_layer_2_loss: 11.1005\n","Epoch 7/20\n","392/392 [==============================] - 280s 714ms/step - loss: 26.5786 - yolo_layer_loss: 5.2778 - yolo_layer_1_loss: 4.5137 - yolo_layer_2_loss: 9.9297 - val_loss: 27.0545 - val_yolo_layer_loss: 6.3470 - val_yolo_layer_1_loss: 3.5790 - val_yolo_layer_2_loss: 10.6013\n","Epoch 8/20\n","392/392 [==============================] - 270s 688ms/step - loss: 25.0645 - yolo_layer_loss: 4.6870 - yolo_layer_1_loss: 3.9923 - yolo_layer_2_loss: 9.9669 - val_loss: 27.3592 - val_yolo_layer_loss: 6.3365 - val_yolo_layer_1_loss: 3.9168 - val_yolo_layer_2_loss: 11.0011\n","Epoch 9/20\n","392/392 [==============================] - 273s 696ms/step - loss: 24.4997 - yolo_layer_loss: 4.6511 - yolo_layer_1_loss: 4.0176 - yolo_layer_2_loss: 9.8121 - val_loss: 27.1150 - val_yolo_layer_loss: 5.7483 - val_yolo_layer_1_loss: 4.1129 - val_yolo_layer_2_loss: 11.4728\n","Epoch 10/20\n","392/392 [==============================] - 259s 661ms/step - loss: 23.5472 - yolo_layer_loss: 4.3708 - yolo_layer_1_loss: 3.6924 - yolo_layer_2_loss: 9.7815 - val_loss: 27.3936 - val_yolo_layer_loss: 7.4600 - val_yolo_layer_1_loss: 3.3426 - val_yolo_layer_2_loss: 11.1084\n","Epoch 11/20\n","392/392 [==============================] - 283s 721ms/step - loss: 23.5807 - yolo_layer_loss: 4.6796 - yolo_layer_1_loss: 4.0679 - yolo_layer_2_loss: 9.4148 - val_loss: 23.4078 - val_yolo_layer_loss: 4.6543 - val_yolo_layer_1_loss: 2.8493 - val_yolo_layer_2_loss: 10.6678\n","Epoch 12/20\n","392/392 [==============================] - 277s 705ms/step - loss: 22.9088 - yolo_layer_loss: 4.3575 - yolo_layer_1_loss: 4.0158 - yolo_layer_2_loss: 9.3610 - val_loss: 24.2517 - val_yolo_layer_loss: 5.6713 - val_yolo_layer_1_loss: 3.0244 - val_yolo_layer_2_loss: 10.5617\n","Epoch 13/20\n","392/392 [==============================] - 262s 666ms/step - loss: 22.0127 - yolo_layer_loss: 4.0834 - yolo_layer_1_loss: 3.6868 - yolo_layer_2_loss: 9.2946 - val_loss: 23.5026 - val_yolo_layer_loss: 5.0801 - val_yolo_layer_1_loss: 3.0504 - val_yolo_layer_2_loss: 10.5629\n","Epoch 14/20\n","392/392 [==============================] - 252s 641ms/step - loss: 21.1759 - yolo_layer_loss: 3.8184 - yolo_layer_1_loss: 3.0738 - yolo_layer_2_loss: 9.5190 - val_loss: 24.3803 - val_yolo_layer_loss: 6.2161 - val_yolo_layer_1_loss: 3.0122 - val_yolo_layer_2_loss: 10.5225\n","Epoch 15/20\n","392/392 [==============================] - 272s 693ms/step - loss: 21.6203 - yolo_layer_loss: 4.0095 - yolo_layer_1_loss: 3.8477 - yolo_layer_2_loss: 9.1728 - val_loss: 24.6569 - val_yolo_layer_loss: 6.3405 - val_yolo_layer_1_loss: 3.6842 - val_yolo_layer_2_loss: 10.1566\n","Epoch 16/20\n","392/392 [==============================] - 275s 701ms/step - loss: 22.2251 - yolo_layer_loss: 4.6986 - yolo_layer_1_loss: 4.3952 - yolo_layer_2_loss: 8.6910 - val_loss: 23.5789 - val_yolo_layer_loss: 5.0533 - val_yolo_layer_1_loss: 3.8519 - val_yolo_layer_2_loss: 10.3431\n","Epoch 17/20\n","392/392 [==============================] - 252s 642ms/step - loss: 19.6195 - yolo_layer_loss: 3.4083 - yolo_layer_1_loss: 3.3882 - yolo_layer_2_loss: 8.4977 - val_loss: 22.0186 - val_yolo_layer_loss: 4.0292 - val_yolo_layer_1_loss: 3.3396 - val_yolo_layer_2_loss: 10.3393\n","Epoch 18/20\n","392/392 [==============================] - 261s 664ms/step - loss: 19.5687 - yolo_layer_loss: 3.3341 - yolo_layer_1_loss: 3.8142 - yolo_layer_2_loss: 8.1146 - val_loss: 23.8301 - val_yolo_layer_loss: 5.2842 - val_yolo_layer_1_loss: 4.3046 - val_yolo_layer_2_loss: 9.9490\n","Epoch 19/20\n","392/392 [==============================] - 268s 683ms/step - loss: 19.2010 - yolo_layer_loss: 3.3182 - yolo_layer_1_loss: 3.5281 - yolo_layer_2_loss: 8.0668 - val_loss: 22.4632 - val_yolo_layer_loss: 4.4469 - val_yolo_layer_1_loss: 3.7051 - val_yolo_layer_2_loss: 10.0350\n","Epoch 20/20\n","392/392 [==============================] - 273s 695ms/step - loss: 18.6401 - yolo_layer_loss: 3.1329 - yolo_layer_1_loss: 3.3433 - yolo_layer_2_loss: 7.8915 - val_loss: 22.2145 - val_yolo_layer_loss: 4.6124 - val_yolo_layer_1_loss: 3.4434 - val_yolo_layer_2_loss: 9.8973\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pdN1-QjBzXJ","executionInfo":{"status":"ok","timestamp":1621652928874,"user_tz":-270,"elapsed":1190,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"cbce2225-dfc7-4539-80be-6d45867db40f"},"source":["!ls ./datasets/fire-dataset-outdoor-d2n/models/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["detection_model-ex-001--loss-0059.472.h5\n","detection_model-ex-002--loss-0033.573.h5\n","detection_model-ex-003--loss-0030.310.h5\n","detection_model-ex-004--loss-0028.396.h5\n","detection_model-ex-005--loss-0027.529.h5\n","detection_model-ex-006--loss-0026.434.h5\n","detection_model-ex-007--loss-0025.796.h5\n","detection_model-ex-008--loss-0024.698.h5\n","detection_model-ex-009--loss-0024.197.h5\n","detection_model-ex-010--loss-0023.253.h5\n","detection_model-ex-012--loss-0022.952.h5\n","detection_model-ex-013--loss-0022.186.h5\n","detection_model-ex-014--loss-0021.301.h5\n","detection_model-ex-017--loss-0019.454.h5\n","detection_model-ex-018--loss-0019.417.h5\n","detection_model-ex-019--loss-0019.391.h5\n","detection_model-ex-020--loss-0019.185.h5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"he-5CQe3DADn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622815873413,"user_tz":-270,"elapsed":9197,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"53b6dccf-6984-4d8b-d958-197d1c7ce0d0"},"source":["# پس از آموزش باید نام بهترین مدل (آخرین مدل ذخیره شده در لیست بالا) در سلول بعدی به جای نام مدل قرار داده شود.\n","# در صورتی که مایلید از مدل از پیش آموزش دیده استفاده کنید، به جای آموزش بالا، دستورات زیر را فعال و اجرا کنید تا مدل قبلی دانلود شود\n","\n","# !gdown https://drive.google.com/uc?id=1HKs4RZk6sBmnr8sSHl62iYZtGyte8TVN\n","# !mkdir ./datasets/fire-dataset-outdoor-d2n/models\n","# !mv detection_model-ex-020--loss-0019.185.h5 ./datasets/fire-dataset-outdoor-d2n/models/\n","# !gdown https://drive.google.com/uc?id=1-17005x7j_PJ0OHaF8q-gyWl2fc_Od5X\n","# !mkdir ./datasets/fire-dataset-outdoor-d2n/json\n","# !mv detection_config.json ./datasets/fire-dataset-outdoor-d2n/json/"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1HKs4RZk6sBmnr8sSHl62iYZtGyte8TVN\n","To: /content/ImageAI/detection_model-ex-020--loss-0019.185.h5\n","247MB [00:03, 73.3MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1-17005x7j_PJ0OHaF8q-gyWl2fc_Od5X\n","To: /content/ImageAI/detection_config.json\n","100% 425/425 [00:00<00:00, 726kB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ExGmVcmGWxDs","executionInfo":{"status":"ok","timestamp":1622815893567,"user_tz":-270,"elapsed":9921,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"a757df42-2e25-4435-ec07-49fe1de23210"},"source":["%%time\n","from imageai.Detection.Custom import DetectionModelTrainer\n","\n","trainer = DetectionModelTrainer()\n","trainer.setModelTypeAsYOLOv3()\n","trainer.setDataDirectory(data_directory=\"./datasets/\"+ds_name)\n","metrics = trainer.evaluateModel(model_path=\"./datasets/\"+ds_name+\"/models/detection_model-ex-020--loss-0019.185.h5\",\\\n","                                json_path=\"./datasets/\"+ds_name+\"/json/detection_config.json\",\\\n","                                iou_threshold=0.2,\\\n","                                object_threshold=0.3, nms_threshold=0.3)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Starting Model evaluation....\n","Evaluating over 60 samples taken from ./datasets/fire-dataset-outdoor-d2n/validation\n","Training over 390 samples  given at ./datasets/fire-dataset-outdoor-d2n/train\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","Model File:  ./datasets/fire-dataset-outdoor-d2n/models/detection_model-ex-020--loss-0019.185.h5 \n","\n","Evaluation samples:  60\n","Using IoU:  0.2\n","Using Object Threshold:  0.3\n","Using Non-Maximum Suppression:  0.3\n","fire: 0.7453\n","mAP: 0.7453\n","===============================\n","CPU times: user 9.58 s, sys: 251 ms, total: 9.83 s\n","Wall time: 9.68 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MpWh5PKQ68BE","executionInfo":{"status":"ok","timestamp":1622816444149,"user_tz":-270,"elapsed":13156,"user":{"displayName":"Mahmood Amintoosi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWZ48HqYJJmPdDTueTtb12dMDVlabGiGyYWEXTkA=s64","userId":"06389092743998374259"}},"outputId":"3dd3caa0-704a-4c08-9d5f-8aecc760f35c"},"source":["# درصورتی که از مدل از قبل آموزش دیده استفاده کرده باشید،‌با دستورات زیر می‌توان مدل را روی تصاویر موجود در پوشه \n","# path\n","# اجرا کرد. \n","# اگر از مدل آموزش دیده خود استفاده می‌کنید، نام مدل را باید اصلاح کنید.\n","from PIL import Image\n","import os, sys\n","from imageai.Detection.Custom import CustomObjectDetection\n","\n","ds_name = \"fire-dataset-outdoor-d2n\"\n","\n","path = \"./datasets/\"+ds_name+\"/validation/images/\"\n","dirs = os.listdir( path )\n","# print(dirs)\n","out_path = \"./results_\"+ds_name\n","os.mkdir(out_path)\n","\n","detector = CustomObjectDetection()\n","detector.setModelTypeAsYOLOv3()\n","detector.setModelPath(\"./datasets/\"+ds_name+\"/models/detection_model-ex-020--loss-0019.185.h5\")\n","detector.setJsonPath(\"./datasets/\"+ds_name+\"/json/detection_config.json\")\n","detector.loadModel()\n","\n","for item in dirs:\n","    if os.path.isfile(path+item):\n","        in_im = path+item\n","        out_im = out_path+\"/\"+item\n","        detections = detector.detectObjectsFromImage(input_image=in_im, output_image_path=out_im)\n","\n","# بعد از اجرای کد بالا، تصاویر در پوشه\n","# results_fire-dataset-outdoor-d2n\n","# قرار داده می‌شوند که می‌توان دانلود نمود"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3704: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n","  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n","/content/ImageAI/imageai/Detection/Custom/__init__.py:1248: RuntimeWarning: overflow encountered in exp\n","  return 1. / (1. + np.exp(-x))\n"],"name":"stderr"}]}]}