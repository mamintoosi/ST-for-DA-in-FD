{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_fire_net_main_scale_01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4yxkb0QLPFm"
      },
      "source": [
        "# انتقال سبک با شبکه‌ی مولد رقابتی برای افزایش داده‌های آموزشی شبکه‌های پیچشی در شناسایی شعله‌ی آتش\n",
        "\n",
        "M. Amintoosi, m.amintoosi@gmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgXBdoI94WTD"
      },
      "source": [
        "سرعت اجرا روی \n",
        "\n",
        "P4, 15 GB RAM\n",
        "\n",
        "تقریبا دو برابر \n",
        "\n",
        "Tesla K80 \n",
        "\n",
        "هست. مشخصات کارت گرافیک اختصاص داده شده را می‌توانید با دستور زیر ببینید:\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsD-u1Kk6yKm",
        "outputId": "0e4360e3-d9c2-4a22-be10-c30cab8656aa"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug 21 18:37:28 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P8    35W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E6nQrRQULpy",
        "outputId": "392a80c1-d8c7-46ea-9d57-da54efc264d7"
      },
      "source": [
        "import os, time\n",
        "from google.colab import files\n",
        "if hasattr(time, 'tzset'):\n",
        "    os.environ['TZ'] = 'Asia/Tehran'\n",
        "    time.tzset()\n",
        "print(time.strftime('%X'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22:40:45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UtaKjGbDQw1",
        "outputId": "29d0b360-7fd9-4f40-b296-208caaff6f99"
      },
      "source": [
        "!git clone https://github.com/mamintoosi-papers-codes/ImageAI.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ImageAI' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2xnXw7rD0do",
        "outputId": "f4b48425-7e56-48c4-b441-0ca8623b37c1"
      },
      "source": [
        "%cd ImageAI\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ImageAI\n",
            "--2021-08-21 22:40:46--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights.1’\n",
            "\n",
            "yolov3.weights.1    100%[===================>] 236.52M  65.3MB/s    in 3.9s    \n",
            "\n",
            "2021-08-21 22:40:50 (61.3 MB/s) - ‘yolov3.weights.1’ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dMA5tRoTIeu",
        "outputId": "67378280-8c6d-4302-b812-ffa3eb49577c"
      },
      "source": [
        "from utils.convert_yolo3_to_keras  import make_yolov3_model,WeightReader\n",
        "# define the model\n",
        "model = make_yolov3_model()\n",
        "# load the model weights\n",
        "weight_reader = WeightReader('yolov3.weights')\n",
        "# set the model weights into the model\n",
        "weight_reader.load_weights(model)\n",
        "# save the model to file\n",
        "model.save('pretrained-yolov3.h5')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading weights of convolution #0\n",
            "loading weights of convolution #1\n",
            "loading weights of convolution #2\n",
            "loading weights of convolution #3\n",
            "no convolution #4\n",
            "loading weights of convolution #5\n",
            "loading weights of convolution #6\n",
            "loading weights of convolution #7\n",
            "no convolution #8\n",
            "loading weights of convolution #9\n",
            "loading weights of convolution #10\n",
            "no convolution #11\n",
            "loading weights of convolution #12\n",
            "loading weights of convolution #13\n",
            "loading weights of convolution #14\n",
            "no convolution #15\n",
            "loading weights of convolution #16\n",
            "loading weights of convolution #17\n",
            "no convolution #18\n",
            "loading weights of convolution #19\n",
            "loading weights of convolution #20\n",
            "no convolution #21\n",
            "loading weights of convolution #22\n",
            "loading weights of convolution #23\n",
            "no convolution #24\n",
            "loading weights of convolution #25\n",
            "loading weights of convolution #26\n",
            "no convolution #27\n",
            "loading weights of convolution #28\n",
            "loading weights of convolution #29\n",
            "no convolution #30\n",
            "loading weights of convolution #31\n",
            "loading weights of convolution #32\n",
            "no convolution #33\n",
            "loading weights of convolution #34\n",
            "loading weights of convolution #35\n",
            "no convolution #36\n",
            "loading weights of convolution #37\n",
            "loading weights of convolution #38\n",
            "loading weights of convolution #39\n",
            "no convolution #40\n",
            "loading weights of convolution #41\n",
            "loading weights of convolution #42\n",
            "no convolution #43\n",
            "loading weights of convolution #44\n",
            "loading weights of convolution #45\n",
            "no convolution #46\n",
            "loading weights of convolution #47\n",
            "loading weights of convolution #48\n",
            "no convolution #49\n",
            "loading weights of convolution #50\n",
            "loading weights of convolution #51\n",
            "no convolution #52\n",
            "loading weights of convolution #53\n",
            "loading weights of convolution #54\n",
            "no convolution #55\n",
            "loading weights of convolution #56\n",
            "loading weights of convolution #57\n",
            "no convolution #58\n",
            "loading weights of convolution #59\n",
            "loading weights of convolution #60\n",
            "no convolution #61\n",
            "loading weights of convolution #62\n",
            "loading weights of convolution #63\n",
            "loading weights of convolution #64\n",
            "no convolution #65\n",
            "loading weights of convolution #66\n",
            "loading weights of convolution #67\n",
            "no convolution #68\n",
            "loading weights of convolution #69\n",
            "loading weights of convolution #70\n",
            "no convolution #71\n",
            "loading weights of convolution #72\n",
            "loading weights of convolution #73\n",
            "no convolution #74\n",
            "loading weights of convolution #75\n",
            "loading weights of convolution #76\n",
            "loading weights of convolution #77\n",
            "loading weights of convolution #78\n",
            "loading weights of convolution #79\n",
            "loading weights of convolution #80\n",
            "loading weights of convolution #81\n",
            "no convolution #82\n",
            "no convolution #83\n",
            "loading weights of convolution #84\n",
            "no convolution #85\n",
            "no convolution #86\n",
            "loading weights of convolution #87\n",
            "loading weights of convolution #88\n",
            "loading weights of convolution #89\n",
            "loading weights of convolution #90\n",
            "loading weights of convolution #91\n",
            "loading weights of convolution #92\n",
            "loading weights of convolution #93\n",
            "no convolution #94\n",
            "no convolution #95\n",
            "loading weights of convolution #96\n",
            "no convolution #97\n",
            "no convolution #98\n",
            "loading weights of convolution #99\n",
            "loading weights of convolution #100\n",
            "loading weights of convolution #101\n",
            "loading weights of convolution #102\n",
            "loading weights of convolution #103\n",
            "loading weights of convolution #104\n",
            "loading weights of convolution #105\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7xoHtErDQ5V",
        "outputId": "4986bec4-7a17-4af8-a8c5-7bd153fbe4a5"
      },
      "source": [
        "!git clone https://github.com/mamintoosi/datasets.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'datasets' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MQrPGCafnx"
      },
      "source": [
        "## آموزش و اجرا بر روی نمونه‌های اصلی، بدون داده‌افزایی: مدل پایه"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjyQlKDShhma"
      },
      "source": [
        "# آموزش مدل بر روی تصاویر آموزشی\n",
        "ds_name = \"fire-dataset-outdoor\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "id": "GEmV3aJmw6AA",
        "outputId": "e5abac9f-6b65-4ac6-9b4c-fe05e0ffd0ff"
      },
      "source": [
        "%%time\n",
        "# آموزش بدون داده‌افزایی\n",
        "# آموزش مدل حدود یک ساعت و ربع طول خواهد کشید. \n",
        "# درصورت تمایل می‌توانید این بخش را اجرا نکرده و در سلول های بعدی از مدل آموزش دیده‌ی پیشین استفاده کنید\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "aug = 'none' # Without any augmentation\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"datasets/\"+ds_name, augmentation = aug)\n",
        "trainer.setTrainConfig(object_names_array=[\"fire\"], batch_size=8, num_experiments=10,\\\n",
        "                       augmentation = aug,\\\n",
        "                       train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.trainModel()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.79\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  datasets/fire-dataset-outdoor_aug-none/json/detection_config.json\n",
            "Evaluating over 60 samples taken from datasets/fire-dataset-outdoor/validation\n",
            "Training over 305 samples  given at datasets/fire-dataset-outdoor/train\n",
            "Training on: \t['fire']\n",
            "Training with Batch Size:  8\n",
            "Number of Training Samples:  305\n",
            "Number of Validation Samples:  60\n",
            "Number of Experiments:  10\n",
            "Training with transfer learning from pretrained Model\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 43/312 [===>..........................] - ETA: 3:43 - loss: 114.6709 - yolo_layer_loss: 15.1315 - yolo_layer_1_loss: 29.7495 - yolo_layer_2_loss: 58.2100"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5d9ec4f5ff46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# آموزش بدون داده\\u200cافزایی\\n# آموزش مدل حدود یک ساعت و ربع طول خواهد کشید. \\n# درصورت تمایل می\\u200cتوانید این بخش را اجرا نکرده و در سلول های بعدی از مدل آموزش دیده\\u200cی پیشین استفاده کنید\\nfrom imageai.Detection.Custom import DetectionModelTrainer\\naug = \\'none\\' # Without any augmentation\\ntrainer = DetectionModelTrainer()\\ntrainer.setModelTypeAsYOLOv3()\\ntrainer.setDataDirectory(data_directory=\"datasets/\"+ds_name, augmentation = aug)\\ntrainer.setTrainConfig(object_names_array=[\"fire\"], batch_size=8, num_experiments=10,\\\\\\n                       augmentation = aug,\\\\\\n                       train_from_pretrained_model=\"pretrained-yolov3.h5\")\\ntrainer.trainModel()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/content/ImageAI/imageai/Detection/Custom/__init__.py\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1987\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    851\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    844\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1286\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3632\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;31m# Run forward pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    789\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 415\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     output, mean, variance = control_flow_util.smart_cond(\n\u001b[0;32m--> 612\u001b[0;31m         training, train_op, _fused_batch_norm_inference)\n\u001b[0m\u001b[1;32m    613\u001b[0m     \u001b[0mvariance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_add_or_remove_bessels_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m    105\u001b[0m   return tf.__internal__.smart_cond.smart_cond(\n\u001b[0;32m--> 106\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    585\u001b[0m           \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m           exponential_avg_factor=exponential_avg_factor)\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fused_batch_norm_training_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36mfused_batch_norm\u001b[0;34m(x, scale, offset, mean, variance, epsilon, data_format, is_training, name, exponential_avg_factor)\u001b[0m\n\u001b[1;32m   1676\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m       \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1678\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1679\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_v3\u001b[0;34m(x, scale, offset, mean, variance, epsilon, exponential_avg_factor, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4269\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4270\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4271\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4272\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,256,56,56] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:FusedBatchNormV3]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_ExuhCF5NNR",
        "outputId": "3092b70c-abae-4390-f5f0-db2b8d34619e"
      },
      "source": [
        "# print(\"datasets/\"+ds_name)\n",
        "# !ls ./datasets\n",
        "# print('\\n')\n",
        "# !ls ./datasets/fire-dataset-outdoor\n",
        "# print('\\n')\n",
        "!ls ./datasets/fire-dataset-outdoor_aug-none/models"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "detection_model-ex-001--loss-0049.913.h5\n",
            "detection_model-ex-002--loss-0030.780.h5\n",
            "detection_model-ex-003--loss-0027.712.h5\n",
            "detection_model-ex-004--loss-0026.044.h5\n",
            "detection_model-ex-005--loss-0024.261.h5\n",
            "detection_model-ex-006--loss-0022.473.h5\n",
            "detection_model-ex-007--loss-0021.327.h5\n",
            "detection_model-ex-008--loss-0020.391.h5\n",
            "detection_model-ex-009--loss-0019.717.h5\n",
            "detection_model-ex-010--loss-0018.960.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "YVERgCGY5NSb",
        "outputId": "c6018ed1-5869-4842-ec2d-2c89f95c9a38"
      },
      "source": [
        "%%time\n",
        "# ارزیابی بهترین مدل بالا\n",
        "# ذکر شود model_path نام بهترین مدل بالا باید در \n",
        "ds_name = \"fire-dataset-outdoor\"\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"./datasets/\"+ds_name)\n",
        "metrics = trainer.evaluateModel(model_path=\"./datasets/\"+ds_name+\"_aug-none/models/detection_model-ex-010--loss-0018.960.h5\",\\\n",
        "                                json_path=\"./datasets/\"+ds_name+\"_aug-none/json/detection_config.json\",\\\n",
        "                                iou_threshold=0.2,\\\n",
        "                                object_threshold=0.3, nms_threshold=0.3)\n",
        "# اگر روال ارزیابی بیشتر از یک دقیقه طول کشید، به این معنی است که مدل به خوبی آموزش ندیده است.\n",
        "# اجرا باید متوقف شده و دوباره مدل آموزش داده شود"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Model evaluation....\n",
            "Evaluating over 60 samples taken from ./datasets/fire-dataset-outdoor/validation\n",
            "Training over 305 samples  given at ./datasets/fire-dataset-outdoor/train\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d3654c63c12b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# ارزیابی بهترین مدل بالا\\n# ذکر شود model_path نام بهترین مدل بالا باید در \\nds_name = \"fire-dataset-outdoor\"\\nfrom imageai.Detection.Custom import DetectionModelTrainer\\n\\ntrainer = DetectionModelTrainer()\\ntrainer.setModelTypeAsYOLOv3()\\ntrainer.setDataDirectory(data_directory=\"./datasets/\"+ds_name)\\nmetrics = trainer.evaluateModel(model_path=\"./datasets/\"+ds_name+\"_aug-none/models/detection_model-ex-010--loss-0018.960.h5\",\\\\\\n                                json_path=\"./datasets/\"+ds_name+\"_aug-none/json/detection_config.json\",\\\\\\n                                iou_threshold=0.2,\\\\\\n                                object_threshold=0.3, nms_threshold=0.3)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/content/ImageAI/imageai/Detection/Custom/__init__.py\u001b[0m in \u001b[0;36mevaluateModel\u001b[0;34m(self, model_path, json_path, batch_size, iou_threshold, object_threshold, nms_threshold)\u001b[0m\n\u001b[1;32m    429\u001b[0m                     \u001b[0;31m# compute mAP for all the classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                     average_precisions = evaluate(infer_model, valid_generator, iou_threshold=iou_threshold,\n\u001b[0;32m--> 431\u001b[0;31m                                                   obj_thresh=object_threshold, nms_thresh=nms_threshold)\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                     result_dict = {\n",
            "\u001b[0;32m/content/ImageAI/imageai/Detection/Custom/utils/utils.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, generator, iou_threshold, obj_thresh, nms_thresh, net_h, net_w, save_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# make the boxes and the labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mpred_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_yolo_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_boxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ImageAI/imageai/Detection/Custom/utils/utils.py\u001b[0m in \u001b[0;36mget_yolo_boxes\u001b[0;34m(model, images, net_h, net_w, anchors, obj_thresh, nms_thresh)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m# suppress non-maximal boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mdo_nms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mbatch_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ImageAI/imageai/Detection/Custom/utils/utils.py\u001b[0m in \u001b[0;36mdo_nms\u001b[0;34m(boxes, nms_thresh)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mindex_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnms_thresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                     \u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ImageAI/imageai/Detection/Custom/utils/bbox.py\u001b[0m in \u001b[0;36mbbox_iou\u001b[0;34m(box1, box2)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0munion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintersect\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdraw_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t8tlM7C5NYq"
      },
      "source": [
        "# !cp datasets/fire-dataset-outdoor_aug-none/models/detection_model-ex-010--loss-0018.252.h5 '/content/gdrive/My Drive/models/fire-10-epoch/outdoor/none/'\n",
        "# !cp datasets/fire-dataset-outdoor_aug-none/json/detection_config.json '/content/gdrive/My Drive/models/fire-10-epoch/outdoor/none/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S3dWXGDSU4s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88f416e2-3228-462e-84b6-8c051870ec4e"
      },
      "source": [
        "# درصورتی که از مدل از قبل آموزش دیده استفاده کرده باشید،‌\n",
        "# با دستورات زیر می‌توان مدل را روی تصاویر موجود در پوشه \n",
        "# path\n",
        "# اجرا کرد. \n",
        "# اگر از مدل آموزش دیده خود استفاده می‌کنید، نام مدل را باید اصلاح کنید.\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "ds_name = \"fire-dataset-outdoor\"\n",
        "\n",
        "path = \"./datasets/\"+ds_name+\"/validation/images/\"\n",
        "dirs = os.listdir( path )\n",
        "# print(dirs)\n",
        "out_path = \"./results_\"+ds_name+\"_aug-none\"\n",
        "os.mkdir(out_path)\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath(\"./datasets/\"+ds_name+\"_aug-none/models/detection_model-ex-010--loss-0018.960.h5\")\n",
        "detector.setJsonPath(\"./datasets/\"+ds_name+\"_aug-none/json/detection_config.json\")\n",
        "detector.loadModel()\n",
        "\n",
        "for item in dirs:\n",
        "    if os.path.isfile(path+item):\n",
        "        in_im = path+item\n",
        "        out_im = out_path+\"/\"+item\n",
        "        detections = detector.detectObjectsFromImage(input_image=in_im, output_image_path=out_im)\n",
        "\n",
        "# بعد از اجرای کد بالا، تصاویر در پوشه\n",
        "# results_fire-dataset-outdoor_aug-none\n",
        "# قرار داده می‌شوند که می‌توان دانلود نمود\n",
        "!zip -r -q results_fire-dataset-outdoor_aug-none.zip results_fire-dataset-outdoor_aug-none/\n",
        "files.download('results_fire-dataset-outdoor_aug-none.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  adding: results_fire-dataset-outdoor/ (stored 0%)\n",
            "  adding: results_fire-dataset-outdoor/img (10).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (29).jpg (deflated 4%)\n",
            "  adding: results_fire-dataset-outdoor/img (17).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/img (4).jpg (deflated 7%)\n",
            "  adding: results_fire-dataset-outdoor/pic (20).jpg (deflated 7%)\n",
            "  adding: results_fire-dataset-outdoor/img (6).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/img (7).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (16).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/pic (11).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/pic (17).jpg (deflated 10%)\n",
            "  adding: results_fire-dataset-outdoor/pic (5).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/img (22).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/pic (4).jpg (deflated 7%)\n",
            "  adding: results_fire-dataset-outdoor/img (19).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/pic (24).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (9).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/img (3).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/img (12).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (6).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/pic (12).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/pic (15).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (21).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (3).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (1).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/img (16).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/pic (19).jpg (deflated 7%)\n",
            "  adding: results_fire-dataset-outdoor/pic (7).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/img (5).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/pic (22).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/img (15).jpg (deflated 7%)\n",
            "  adding: results_fire-dataset-outdoor/img (21).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/img (14).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/img (24).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/img (29).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (30).jpg (deflated 4%)\n",
            "  adding: results_fire-dataset-outdoor/pic (26).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/pic (13).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/img (13).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (23).jpg (deflated 9%)\n",
            "  adding: results_fire-dataset-outdoor/img (27).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/img (26).jpg (deflated 9%)\n",
            "  adding: results_fire-dataset-outdoor/img (8).jpg (deflated 4%)\n",
            "  adding: results_fire-dataset-outdoor/img (9).jpg (deflated 7%)\n",
            "  adding: results_fire-dataset-outdoor/img (23).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/img (1).jpg (deflated 7%)\n",
            "  adding: results_fire-dataset-outdoor/img (11).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/pic (14).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/img (2).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/img (30).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/pic (28).jpg (deflated 10%)\n",
            "  adding: results_fire-dataset-outdoor/pic (25).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (8).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/img (28).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/pic (27).jpg (deflated 5%)\n",
            "  adding: results_fire-dataset-outdoor/pic (10).jpg (deflated 4%)\n",
            "  adding: results_fire-dataset-outdoor/img (18).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/pic (18).jpg (deflated 7%)\n",
            "  adding: results_fire-dataset-outdoor/pic (2).jpg (deflated 8%)\n",
            "  adding: results_fire-dataset-outdoor/img (20).jpg (deflated 6%)\n",
            "  adding: results_fire-dataset-outdoor/img (25).jpg (deflated 5%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1985b710-d051-44bc-b5dc-75e9f9c08bc0\", \"results_fire-dataset-outdoor.zip\", 902935)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfob04LuSVGS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4ZDCKf7os_"
      },
      "source": [
        "## آموزش مدل بر روی داده های آموزشی به همراه داده‌افزایی از نوع تغییرمقیاس و برش"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pk3JCyfGBD0",
        "outputId": "0021df9d-7f30-4c50-a79f-6fbbc582ec5d"
      },
      "source": [
        "%%time\n",
        "# آموزش با داده‌افزایی\n",
        "# آموزش مدل حدود یک ساعت و ربع طول خواهد کشید. \n",
        "# درصورت تمایل می‌توانید این بخش را اجرا نکرده و در سلول های بعدی از مدل آموزش دیده‌ی پیشین استفاده کنید\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "aug = 'scale' # Scale and Crop augmentation\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"datasets/\"+ds_name, augmentation = aug)\n",
        "trainer.setTrainConfig(object_names_array=[\"fire\"], batch_size=8, num_experiments=10,\\\n",
        "                       augmentation = aug,\\\n",
        "                       train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.trainModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.78\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  datasets/fire-dataset-outdoor_augscale/json/detection_config.json\n",
            "Evaluating over 60 samples taken from datasets/fire-dataset-outdoor/validation\n",
            "Training over 305 samples  given at datasets/fire-dataset-outdoor/train\n",
            "Training on: \t['fire']\n",
            "Training with Batch Size:  8\n",
            "Number of Training Samples:  305\n",
            "Number of Validation Samples:  60\n",
            "Number of Experiments:  20\n",
            "Training with transfer learning from pretrained Model\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "312/312 [==============================] - 259s 726ms/step - loss: 61.7141 - yolo_layer_loss: 9.2362 - yolo_layer_1_loss: 12.9065 - yolo_layer_2_loss: 28.0575 - val_loss: 43.0646 - val_yolo_layer_loss: 9.5209 - val_yolo_layer_1_loss: 9.0363 - val_yolo_layer_2_loss: 13.2167\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 2/20\n",
            "312/312 [==============================] - 212s 681ms/step - loss: 32.5667 - yolo_layer_loss: 4.8815 - yolo_layer_1_loss: 6.4775 - yolo_layer_2_loss: 10.7549 - val_loss: 34.1248 - val_yolo_layer_loss: 7.3498 - val_yolo_layer_1_loss: 6.1344 - val_yolo_layer_2_loss: 10.9580\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 3/20\n",
            "312/312 [==============================] - 234s 750ms/step - loss: 29.4085 - yolo_layer_loss: 4.6089 - yolo_layer_1_loss: 6.2219 - yolo_layer_2_loss: 9.0969 - val_loss: 32.2492 - val_yolo_layer_loss: 6.4703 - val_yolo_layer_1_loss: 5.5251 - val_yolo_layer_2_loss: 10.9477\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 4/20\n",
            "312/312 [==============================] - 233s 745ms/step - loss: 27.5405 - yolo_layer_loss: 4.2103 - yolo_layer_1_loss: 5.4419 - yolo_layer_2_loss: 8.8349 - val_loss: 30.7095 - val_yolo_layer_loss: 6.4889 - val_yolo_layer_1_loss: 5.7152 - val_yolo_layer_2_loss: 9.7931\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 5/20\n",
            "312/312 [==============================] - 228s 729ms/step - loss: 25.5246 - yolo_layer_loss: 3.7060 - yolo_layer_1_loss: 5.2455 - yolo_layer_2_loss: 8.0220 - val_loss: 32.0227 - val_yolo_layer_loss: 8.3748 - val_yolo_layer_1_loss: 5.5961 - val_yolo_layer_2_loss: 9.6883\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 6/20\n",
            "312/312 [==============================] - 236s 757ms/step - loss: 24.5658 - yolo_layer_loss: 3.7189 - yolo_layer_1_loss: 5.1065 - yolo_layer_2_loss: 7.5283 - val_loss: 29.5452 - val_yolo_layer_loss: 5.3926 - val_yolo_layer_1_loss: 5.9278 - val_yolo_layer_2_loss: 10.1418\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 7/20\n",
            "312/312 [==============================] - 241s 772ms/step - loss: 23.4255 - yolo_layer_loss: 3.7464 - yolo_layer_1_loss: 4.7311 - yolo_layer_2_loss: 7.0085 - val_loss: 29.7478 - val_yolo_layer_loss: 6.7278 - val_yolo_layer_1_loss: 5.6015 - val_yolo_layer_2_loss: 9.6128\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 8/20\n",
            "312/312 [==============================] - 223s 714ms/step - loss: 21.9771 - yolo_layer_loss: 3.1048 - yolo_layer_1_loss: 4.4469 - yolo_layer_2_loss: 6.7461 - val_loss: 28.8719 - val_yolo_layer_loss: 5.0843 - val_yolo_layer_1_loss: 5.9819 - val_yolo_layer_2_loss: 10.2393\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 9/20\n",
            "312/312 [==============================] - 232s 744ms/step - loss: 21.1328 - yolo_layer_loss: 3.0338 - yolo_layer_1_loss: 4.4216 - yolo_layer_2_loss: 6.1908 - val_loss: 30.6848 - val_yolo_layer_loss: 6.6392 - val_yolo_layer_1_loss: 5.6406 - val_yolo_layer_2_loss: 11.0396\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 10/20\n",
            "312/312 [==============================] - 232s 743ms/step - loss: 20.7690 - yolo_layer_loss: 3.0898 - yolo_layer_1_loss: 4.0972 - yolo_layer_2_loss: 6.3139 - val_loss: 28.3396 - val_yolo_layer_loss: 6.2068 - val_yolo_layer_1_loss: 5.2975 - val_yolo_layer_2_loss: 9.6369\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 11/20\n",
            "312/312 [==============================] - 223s 715ms/step - loss: 19.6705 - yolo_layer_loss: 2.8944 - yolo_layer_1_loss: 3.8095 - yolo_layer_2_loss: 5.8671 - val_loss: 27.6831 - val_yolo_layer_loss: 5.6628 - val_yolo_layer_1_loss: 5.4480 - val_yolo_layer_2_loss: 9.5541\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 12/20\n",
            "312/312 [==============================] - 243s 777ms/step - loss: 19.4960 - yolo_layer_loss: 3.0388 - yolo_layer_1_loss: 4.0849 - yolo_layer_2_loss: 5.4074 - val_loss: 28.1848 - val_yolo_layer_loss: 5.4645 - val_yolo_layer_1_loss: 5.4484 - val_yolo_layer_2_loss: 10.3603\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 13/20\n",
            "312/312 [==============================] - 232s 745ms/step - loss: 18.9282 - yolo_layer_loss: 2.7631 - yolo_layer_1_loss: 3.8403 - yolo_layer_2_loss: 5.4757 - val_loss: 25.7283 - val_yolo_layer_loss: 3.7313 - val_yolo_layer_1_loss: 5.1340 - val_yolo_layer_2_loss: 10.0751\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 14/20\n",
            "312/312 [==============================] - 229s 734ms/step - loss: 18.4868 - yolo_layer_loss: 2.5175 - yolo_layer_1_loss: 3.8337 - yolo_layer_2_loss: 5.4081 - val_loss: 28.1944 - val_yolo_layer_loss: 5.4059 - val_yolo_layer_1_loss: 6.1866 - val_yolo_layer_2_loss: 9.9604\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 15/20\n",
            "312/312 [==============================] - 234s 748ms/step - loss: 18.4818 - yolo_layer_loss: 2.8955 - yolo_layer_1_loss: 3.7741 - yolo_layer_2_loss: 5.2167 - val_loss: 27.3244 - val_yolo_layer_loss: 4.2015 - val_yolo_layer_1_loss: 5.8998 - val_yolo_layer_2_loss: 10.6831\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 16/20\n",
            "312/312 [==============================] - 236s 756ms/step - loss: 17.7103 - yolo_layer_loss: 2.6823 - yolo_layer_1_loss: 3.6596 - yolo_layer_2_loss: 4.8708 - val_loss: 26.8652 - val_yolo_layer_loss: 5.0534 - val_yolo_layer_1_loss: 5.2899 - val_yolo_layer_2_loss: 10.0778\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 17/20\n",
            "312/312 [==============================] - 228s 729ms/step - loss: 17.1305 - yolo_layer_loss: 2.5561 - yolo_layer_1_loss: 3.2486 - yolo_layer_2_loss: 4.9307 - val_loss: 28.7325 - val_yolo_layer_loss: 6.5318 - val_yolo_layer_1_loss: 6.3565 - val_yolo_layer_2_loss: 9.4964\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 18/20\n",
            "312/312 [==============================] - 225s 721ms/step - loss: 17.0008 - yolo_layer_loss: 2.5621 - yolo_layer_1_loss: 3.2783 - yolo_layer_2_loss: 4.8474 - val_loss: 27.3769 - val_yolo_layer_loss: 4.5189 - val_yolo_layer_1_loss: 5.8761 - val_yolo_layer_2_loss: 10.7025\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 19/20\n",
            "312/312 [==============================] - 222s 710ms/step - loss: 17.0364 - yolo_layer_loss: 2.3400 - yolo_layer_1_loss: 3.3055 - yolo_layer_2_loss: 5.1675 - val_loss: 28.4502 - val_yolo_layer_loss: 6.3249 - val_yolo_layer_1_loss: 5.9914 - val_yolo_layer_2_loss: 9.9605\n",
            "Epoch 20/20\n",
            "312/312 [==============================] - 226s 724ms/step - loss: 16.3811 - yolo_layer_loss: 2.5053 - yolo_layer_1_loss: 3.1777 - yolo_layer_2_loss: 4.5652 - val_loss: 26.7833 - val_yolo_layer_loss: 5.2140 - val_yolo_layer_1_loss: 5.0786 - val_yolo_layer_2_loss: 10.4038\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2rO7zi2GBPO",
        "outputId": "307b17b6-6317-49a4-fa2b-287117e6e15e"
      },
      "source": [
        "# print(\"datasets/\"+ds_name)\n",
        "# !ls ./datasets\n",
        "# print('\\n')\n",
        "# !ls ./datasets/fire-dataset-outdoor\n",
        "# print('\\n')\n",
        "!ls ./datasets/fire-dataset-outdoor_aug-scale/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "day2night     fire-dataset-outdoor\t     fire-dataset-outdoor-d2n\n",
            "fire-dataset  fire-dataset-outdoor_augscale  README.md\n",
            "\n",
            "\n",
            "cache  test  train  validation\n",
            "detection_model-ex-001--loss-0061.714.h5\n",
            "detection_model-ex-002--loss-0032.567.h5\n",
            "detection_model-ex-003--loss-0029.409.h5\n",
            "detection_model-ex-004--loss-0027.541.h5\n",
            "detection_model-ex-005--loss-0025.525.h5\n",
            "detection_model-ex-006--loss-0024.566.h5\n",
            "detection_model-ex-007--loss-0023.425.h5\n",
            "detection_model-ex-008--loss-0021.977.h5\n",
            "detection_model-ex-009--loss-0021.133.h5\n",
            "detection_model-ex-010--loss-0020.769.h5\n",
            "detection_model-ex-011--loss-0019.670.h5\n",
            "detection_model-ex-012--loss-0019.496.h5\n",
            "detection_model-ex-013--loss-0018.928.h5\n",
            "detection_model-ex-014--loss-0018.487.h5\n",
            "detection_model-ex-015--loss-0018.482.h5\n",
            "detection_model-ex-016--loss-0017.710.h5\n",
            "detection_model-ex-017--loss-0017.130.h5\n",
            "detection_model-ex-018--loss-0017.001.h5\n",
            "detection_model-ex-020--loss-0016.381.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7hG6S9ROqqE"
      },
      "source": [
        "!cp datasets/fire-dataset-outdoor_augscale/models/detection_model-ex-010--loss-0020.769.h5 '/content/gdrive/My Drive/models/fire-10-epoch/outdoor/scale/'\n",
        "!cp datasets/fire-dataset-outdoor_augscale/json/detection_config.json '/content/gdrive/My Drive/models/fire-10-epoch/outdoor/scale/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdtOVi51v9Ym",
        "outputId": "d494541a-bedd-4c70-d428-b8751dad53ef"
      },
      "source": [
        "%%time\n",
        "# ارزیابی بهترین مدل بالا\n",
        "# ذکر شود model_path نام بهترین مدل بالا باید در \n",
        "ds_name = \"fire-dataset-outdoor\"\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"./datasets/\"+ds_name)\n",
        "metrics = trainer.evaluateModel(model_path=\"./datasets/\"+ds_name+\"_augscale/models/detection_model-ex-010--loss-0020.769.h5\",\\\n",
        "                                json_path=\"./datasets/\"+ds_name+\"_augscale/json/detection_config.json\",\\\n",
        "                                iou_threshold=0.2,\\\n",
        "                                object_threshold=0.3, nms_threshold=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Model evaluation....\n",
            "Evaluating over 60 samples taken from ./datasets/fire-dataset-outdoor/validation\n",
            "Training over 305 samples  given at ./datasets/fire-dataset-outdoor/train\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  ./datasets/fire-dataset-outdoor_augscale/models/detection_model-ex-010--loss-0020.769.h5 \n",
            "\n",
            "Evaluation samples:  60\n",
            "Using IoU:  0.2\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.3\n",
            "fire: 0.6902\n",
            "mAP: 0.6902\n",
            "===============================\n",
            "CPU times: user 8.02 s, sys: 257 ms, total: 8.28 s\n",
            "Wall time: 14.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "gwlnakQ9Ihc6",
        "outputId": "4f6e413a-c2dc-45c7-ada3-7934ff44119c"
      },
      "source": [
        "# درصورتی که از مدل از قبل آموزش دیده استفاده کرده باشید،‌\n",
        "# با دستورات زیر می‌توان مدل را روی تصاویر موجود در پوشه \n",
        "# path\n",
        "# اجرا کرد. \n",
        "# اگر از مدل آموزش دیده خود استفاده می‌کنید، نام مدل را باید اصلاح کنید.\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "ds_name = \"fire-dataset-outdoor\"\n",
        "\n",
        "path = \"./datasets/\"+ds_name+\"/validation/images/\"\n",
        "dirs = os.listdir( path )\n",
        "# print(dirs)\n",
        "out_path = \"./results_\"+ds_name+'aug-scale'\n",
        "os.mkdir(out_path)\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath(\"./datasets/\"+ds_name+\"_aug-scale/models/detection_model-ex-010--loss-0020.769.h5\")\n",
        "detector.setJsonPath(\"./datasets/\"+ds_name+\"_aug-scale/json/detection_config.json\")\n",
        "detector.loadModel()\n",
        "\n",
        "for item in dirs:\n",
        "    if os.path.isfile(path+item):\n",
        "        in_im = path+item\n",
        "        out_im = out_path+\"/\"+item\n",
        "        detections = detector.detectObjectsFromImage(input_image=in_im, output_image_path=out_im)\n",
        "\n",
        "# بعد از اجرای کد بالا، تصاویر در پوشه\n",
        "# results_fire-dataset-outdoor_aug-scale\n",
        "# قرار داده می‌شوند که می‌توان دانلود نمود\n",
        "!zip -r -q results_fire-dataset-outdoor_aug-scale.zip results_fire-dataset-outdoor_aug-scale/\n",
        "files.download('results_fire-dataset-outdoor_aug-scale.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_80b6cfe3-c277-49ac-9481-47ba04d26cc8\", \"results_fire-dataset-outdoor-scale.zip\", 1022535)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUSnJIXAGBZF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN4lEmbqaIdD"
      },
      "source": [
        "# D2N آموزش و اجرا بر روی نمونه‌های اضافه شده با انتقال سبک عصبی، مدل \n",
        "## آموزش مدل بر روی داده های آموزشی و روز به شب شده بدون داده‌افزایی‌های مرسوم\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MuBN0ownBPPC",
        "outputId": "909c107a-ca93-4b50-95ff-7d9c4d24972b"
      },
      "source": [
        "# آموزش مدل بر روی تصاویر آموزشی + تصاویر روز به شب شده با انتقال سبک\n",
        "ds_name = \"fire-dataset-outdoor-d2n\"\n",
        "ds_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fire-dataset-outdoor-d2n'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSB_0h5wBSk5",
        "outputId": "61212cfd-e692-47d6-c33f-36cf0e121fde"
      },
      "source": [
        "%%time\n",
        "# آموزش مدل حدود یک ساعت و نیم طول خواهد کشید. \n",
        "# درصورت تمایل می‌توانید این بخش را اجرا نکرده و در سلول های بعدی از مدل آموزش دیده‌ی پیشین استفاده کنید\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "aug = 'none' # Withot regular augmentation\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"datasets/\"+ds_name, augmentation = aug)\n",
        "trainer.setTrainConfig(object_names_array=[\"fire\"], batch_size=8, num_experiments=10,\\\n",
        "                       augmentation = aug,\\\n",
        "                       train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.trainModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.79\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  datasets/fire-dataset-outdoor-d2n/json/detection_config.json\n",
            "Evaluating over 60 samples taken from datasets/fire-dataset-outdoor-d2n/validation\n",
            "Training over 390 samples  given at datasets/fire-dataset-outdoor-d2n/train\n",
            "Training on: \t['fire']\n",
            "Training with Batch Size:  8\n",
            "Number of Training Samples:  390\n",
            "Number of Validation Samples:  60\n",
            "Number of Experiments:  20\n",
            "Training with transfer learning from pretrained Model\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n",
            "Epoch 1/20\n",
            "392/392 [==============================] - 286s 729ms/step - loss: 57.9571 - yolo_layer_3_loss: 10.2456 - yolo_layer_4_loss: 9.8218 - yolo_layer_5_loss: 26.3881 - val_loss: 42.4851 - val_yolo_layer_3_loss: 12.6599 - val_yolo_layer_4_loss: 5.2916 - val_yolo_layer_5_loss: 13.2691\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 2/20\n",
            "392/392 [==============================] - 297s 758ms/step - loss: 32.2586 - yolo_layer_3_loss: 5.8840 - yolo_layer_4_loss: 5.2864 - yolo_layer_5_loss: 10.2314 - val_loss: 32.1740 - val_yolo_layer_3_loss: 5.3583 - val_yolo_layer_4_loss: 4.6198 - val_yolo_layer_5_loss: 11.6864\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 3/20\n",
            "392/392 [==============================] - 274s 698ms/step - loss: 27.3053 - yolo_layer_3_loss: 4.2722 - yolo_layer_4_loss: 3.9844 - yolo_layer_5_loss: 8.8706 - val_loss: 32.8246 - val_yolo_layer_3_loss: 6.9982 - val_yolo_layer_4_loss: 4.9804 - val_yolo_layer_5_loss: 10.9849\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 4/20\n",
            "392/392 [==============================] - 277s 706ms/step - loss: 25.2014 - yolo_layer_3_loss: 3.8199 - yolo_layer_4_loss: 4.0934 - yolo_layer_5_loss: 7.7332 - val_loss: 30.3448 - val_yolo_layer_3_loss: 6.0551 - val_yolo_layer_4_loss: 4.3594 - val_yolo_layer_5_loss: 10.6523\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 5/20\n",
            "392/392 [==============================] - 277s 706ms/step - loss: 23.4931 - yolo_layer_3_loss: 3.6231 - yolo_layer_4_loss: 3.6243 - yolo_layer_5_loss: 7.2123 - val_loss: 28.6832 - val_yolo_layer_3_loss: 4.9685 - val_yolo_layer_4_loss: 4.1682 - val_yolo_layer_5_loss: 10.7626\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 6/20\n",
            "392/392 [==============================] - 270s 687ms/step - loss: 21.7500 - yolo_layer_3_loss: 3.3599 - yolo_layer_4_loss: 3.4848 - yolo_layer_5_loss: 6.3305 - val_loss: 29.7914 - val_yolo_layer_3_loss: 5.5712 - val_yolo_layer_4_loss: 4.6572 - val_yolo_layer_5_loss: 11.1910\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 7/20\n",
            "392/392 [==============================] - 285s 727ms/step - loss: 20.7275 - yolo_layer_3_loss: 3.2930 - yolo_layer_4_loss: 3.4372 - yolo_layer_5_loss: 5.8147 - val_loss: 28.2257 - val_yolo_layer_3_loss: 4.6718 - val_yolo_layer_4_loss: 4.0333 - val_yolo_layer_5_loss: 11.4983\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 8/20\n",
            "392/392 [==============================] - 285s 727ms/step - loss: 19.6604 - yolo_layer_3_loss: 3.3078 - yolo_layer_4_loss: 3.2489 - yolo_layer_5_loss: 5.2285 - val_loss: 28.6850 - val_yolo_layer_3_loss: 3.9874 - val_yolo_layer_4_loss: 4.2062 - val_yolo_layer_5_loss: 12.7553\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 9/20\n",
            "392/392 [==============================] - 286s 729ms/step - loss: 18.6975 - yolo_layer_3_loss: 3.0324 - yolo_layer_4_loss: 3.0577 - yolo_layer_5_loss: 4.9804 - val_loss: 29.8904 - val_yolo_layer_3_loss: 7.5324 - val_yolo_layer_4_loss: 4.4396 - val_yolo_layer_5_loss: 10.4096\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 10/20\n",
            "392/392 [==============================] - 275s 701ms/step - loss: 17.8779 - yolo_layer_3_loss: 2.7782 - yolo_layer_4_loss: 2.8415 - yolo_layer_5_loss: 4.8789 - val_loss: 28.1411 - val_yolo_layer_3_loss: 5.3496 - val_yolo_layer_4_loss: 4.4458 - val_yolo_layer_5_loss: 11.0851\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 11/20\n",
            "392/392 [==============================] - 285s 727ms/step - loss: 17.5480 - yolo_layer_3_loss: 2.9213 - yolo_layer_4_loss: 2.9630 - yolo_layer_5_loss: 4.4892 - val_loss: 28.1271 - val_yolo_layer_3_loss: 4.8887 - val_yolo_layer_4_loss: 4.1846 - val_yolo_layer_5_loss: 11.9814\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 12/20\n",
            "392/392 [==============================] - 282s 718ms/step - loss: 17.1410 - yolo_layer_3_loss: 2.8082 - yolo_layer_4_loss: 2.8054 - yolo_layer_5_loss: 4.5518 - val_loss: 28.9326 - val_yolo_layer_3_loss: 5.9753 - val_yolo_layer_4_loss: 4.4740 - val_yolo_layer_5_loss: 11.6002\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 13/20\n",
            "392/392 [==============================] - 256s 653ms/step - loss: 15.7079 - yolo_layer_3_loss: 2.1837 - yolo_layer_4_loss: 2.3763 - yolo_layer_5_loss: 4.3644 - val_loss: 27.7328 - val_yolo_layer_3_loss: 5.8464 - val_yolo_layer_4_loss: 4.1963 - val_yolo_layer_5_loss: 11.0172\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 14/20\n",
            "392/392 [==============================] - 283s 722ms/step - loss: 15.7470 - yolo_layer_3_loss: 2.5345 - yolo_layer_4_loss: 2.7601 - yolo_layer_5_loss: 3.8536 - val_loss: 29.3636 - val_yolo_layer_3_loss: 7.6105 - val_yolo_layer_4_loss: 4.8618 - val_yolo_layer_5_loss: 10.3818\n",
            "Epoch 15/20\n",
            "392/392 [==============================] - 266s 678ms/step - loss: 15.8233 - yolo_layer_3_loss: 2.5363 - yolo_layer_4_loss: 2.8370 - yolo_layer_5_loss: 4.0544 - val_loss: 27.3305 - val_yolo_layer_3_loss: 4.5033 - val_yolo_layer_4_loss: 3.5836 - val_yolo_layer_5_loss: 12.9240\n",
            "Epoch 16/20\n",
            "392/392 [==============================] - 286s 730ms/step - loss: 12.8859 - yolo_layer_3_loss: 1.8062 - yolo_layer_4_loss: 1.9847 - yolo_layer_5_loss: 2.7873 - val_loss: 26.8071 - val_yolo_layer_3_loss: 5.3230 - val_yolo_layer_4_loss: 3.8961 - val_yolo_layer_5_loss: 11.2921\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 17/20\n",
            "392/392 [==============================] - 274s 698ms/step - loss: 11.9764 - yolo_layer_3_loss: 1.5312 - yolo_layer_4_loss: 1.6721 - yolo_layer_5_loss: 2.4894 - val_loss: 27.0924 - val_yolo_layer_3_loss: 5.2038 - val_yolo_layer_4_loss: 4.2688 - val_yolo_layer_5_loss: 11.3483\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 18/20\n",
            "392/392 [==============================] - 290s 740ms/step - loss: 11.9162 - yolo_layer_3_loss: 1.6215 - yolo_layer_4_loss: 1.6806 - yolo_layer_5_loss: 2.3536 - val_loss: 27.3497 - val_yolo_layer_3_loss: 5.4439 - val_yolo_layer_4_loss: 4.3348 - val_yolo_layer_5_loss: 11.3204\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 19/20\n",
            "392/392 [==============================] - 267s 679ms/step - loss: 11.6066 - yolo_layer_3_loss: 1.4081 - yolo_layer_4_loss: 1.5228 - yolo_layer_5_loss: 2.4381 - val_loss: 27.2433 - val_yolo_layer_3_loss: 4.9428 - val_yolo_layer_4_loss: 4.0488 - val_yolo_layer_5_loss: 12.0262\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 20/20\n",
            "392/392 [==============================] - 271s 690ms/step - loss: 11.2604 - yolo_layer_3_loss: 1.3267 - yolo_layer_4_loss: 1.4607 - yolo_layer_5_loss: 2.2601 - val_loss: 26.9380 - val_yolo_layer_3_loss: 4.9461 - val_yolo_layer_4_loss: 4.1441 - val_yolo_layer_5_loss: 11.6470\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pdN1-QjBzXJ",
        "outputId": "f9a4c34d-371e-49f6-d1a8-9931fa4cbda3"
      },
      "source": [
        "!ls ./datasets/fire-dataset-outdoor-d2n/models/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "detection_model-ex-001--loss-0057.957.h5\n",
            "detection_model-ex-002--loss-0032.259.h5\n",
            "detection_model-ex-003--loss-0027.305.h5\n",
            "detection_model-ex-004--loss-0025.201.h5\n",
            "detection_model-ex-005--loss-0023.493.h5\n",
            "detection_model-ex-006--loss-0021.750.h5\n",
            "detection_model-ex-007--loss-0020.728.h5\n",
            "detection_model-ex-008--loss-0019.660.h5\n",
            "detection_model-ex-009--loss-0018.698.h5\n",
            "detection_model-ex-010--loss-0017.878.h5\n",
            "detection_model-ex-011--loss-0017.548.h5\n",
            "detection_model-ex-012--loss-0017.141.h5\n",
            "detection_model-ex-013--loss-0015.708.h5\n",
            "detection_model-ex-016--loss-0012.886.h5\n",
            "detection_model-ex-017--loss-0011.976.h5\n",
            "detection_model-ex-018--loss-0011.916.h5\n",
            "detection_model-ex-019--loss-0011.607.h5\n",
            "detection_model-ex-020--loss-0011.260.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxBnCUC2N6TH"
      },
      "source": [
        "# !cp datasets/fire-dataset-outdoor-d2n/models/detection_model-ex-010--loss-0017.878.h5 '/content/gdrive/My Drive/models/fire-10-epoch/outdoor-d2n/none/'\n",
        "# !cp datasets/fire-dataset-outdoor-d2n/json/detection_config.json '/content/gdrive/My Drive/models/fire-10-epoch/outdoor-d2n/none/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he-5CQe3DADn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b6dccf-6984-4d8b-d958-197d1c7ce0d0"
      },
      "source": [
        "# پس از آموزش باید نام بهترین مدل (آخرین مدل ذخیره شده در لیست بالا) در سلول بعدی به جای نام مدل قرار داده شود.\n",
        "# در صورتی که مایلید از مدل از پیش آموزش دیده استفاده کنید، به جای آموزش بالا، دستورات زیر را فعال و اجرا کنید تا مدل قبلی دانلود شود\n",
        "\n",
        "# !gdown https://drive.google.com/uc?id=1HKs4RZk6sBmnr8sSHl62iYZtGyte8TVN\n",
        "# !mkdir ./datasets/fire-dataset-outdoor-d2n/models\n",
        "# !mv detection_model-ex-020--loss-0019.185.h5 ./datasets/fire-dataset-outdoor-d2n/models/\n",
        "# !gdown https://drive.google.com/uc?id=1-17005x7j_PJ0OHaF8q-gyWl2fc_Od5X\n",
        "# !mkdir ./datasets/fire-dataset-outdoor-d2n/json\n",
        "# !mv detection_config.json ./datasets/fire-dataset-outdoor-d2n/json/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HKs4RZk6sBmnr8sSHl62iYZtGyte8TVN\n",
            "To: /content/ImageAI/detection_model-ex-020--loss-0019.185.h5\n",
            "247MB [00:03, 73.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-17005x7j_PJ0OHaF8q-gyWl2fc_Od5X\n",
            "To: /content/ImageAI/detection_config.json\n",
            "100% 425/425 [00:00<00:00, 726kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExGmVcmGWxDs",
        "outputId": "255cc8e3-8915-49fa-b772-82cf6f2ea06f"
      },
      "source": [
        "%%time\n",
        "# ارزیابی بهترین مدل بالا\n",
        "# ذکر شود model_path نام بهترین مدل بالا باید در \n",
        "\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"./datasets/\"+ds_name)\n",
        "metrics = trainer.evaluateModel(model_path=\"./datasets/\"+ds_name+\"/models/detection_model-ex-010--loss-0017.878.h5\",\\\n",
        "                                json_path=\"./datasets/\"+ds_name+\"/json/detection_config.json\",\\\n",
        "                                iou_threshold=0.2,\\\n",
        "                                object_threshold=0.3, nms_threshold=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Model evaluation....\n",
            "Evaluating over 60 samples taken from ./datasets/fire-dataset-outdoor-d2n/validation\n",
            "Training over 390 samples  given at ./datasets/fire-dataset-outdoor-d2n/train\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  ./datasets/fire-dataset-outdoor-d2n/models/detection_model-ex-010--loss-0017.878.h5 \n",
            "\n",
            "Evaluation samples:  60\n",
            "Using IoU:  0.2\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.3\n",
            "fire: 0.7236\n",
            "mAP: 0.7236\n",
            "===============================\n",
            "CPU times: user 7.83 s, sys: 151 ms, total: 7.98 s\n",
            "Wall time: 7.91 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "MpWh5PKQ68BE",
        "outputId": "3e2dbed3-bd67-4623-b75c-0b76e151e6d8"
      },
      "source": [
        "# درصورتی که از مدل از قبل آموزش دیده استفاده کرده باشید،‌\n",
        "# با دستورات زیر می‌توان مدل را روی تصاویر موجود در پوشه \n",
        "# path\n",
        "# اجرا کرد. \n",
        "# اگر از مدل آموزش دیده خود استفاده می‌کنید، نام مدل را باید اصلاح کنید.\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "ds_name = \"fire-dataset-outdoor-d2n\"\n",
        "\n",
        "path = \"./datasets/\"+ds_name+\"aug-none/validation/images/\"\n",
        "dirs = os.listdir( path )\n",
        "# print(dirs)\n",
        "out_path = \"./results_\"+ds_name\n",
        "os.mkdir(out_path)\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath(\"./datasets/\"+ds_name+\"_aug-none/models/detection_model-ex-010--loss-0017.878.h5\")\n",
        "detector.setJsonPath(\"./datasets/\"+ds_name+\"_aug-none/json/detection_config.json\")\n",
        "detector.loadModel()\n",
        "\n",
        "for item in dirs:\n",
        "    if os.path.isfile(path+item):\n",
        "        in_im = path+item\n",
        "        out_im = out_path+\"/\"+item\n",
        "        detections = detector.detectObjectsFromImage(input_image=in_im, output_image_path=out_im)\n",
        "\n",
        "# بعد از اجرای کد بالا، تصاویر در پوشه\n",
        "# results_fire-dataset-outdoor-d2n_aug-none\n",
        "# قرار داده می‌شوند که می‌توان دانلود نمود\n",
        "!zip -r -q results_fire-dataset-outdoor-d2n_aug-none.zip results_fire-dataset-outdoor-d2n_aug-none/\n",
        "files.download('results_fire-dataset-outdoor-d2n_aug-none.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4cc4825a-c600-4396-b90f-d23130a7669a\", \"results_fire-dataset-outdoor-d2n.zip\", 936384)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApY2HBLY3JVH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T95WpxnU7IaO"
      },
      "source": [
        "## آموزش مدل بر روی داده های آموزشی و روز به شب شده به همراه داده‌افزایی از نوع تغییرمقیاس و برش"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vYE8IYD3JfW",
        "outputId": "ce2cb1ec-5d93-401a-a160-6fa84a34c37b"
      },
      "source": [
        "%%time\n",
        "ds_name = \"fire-dataset-outdoor-d2n\"\n",
        "# آموزش مدل حدود یک ساعت و نیم طول خواهد کشید. \n",
        "# درصورت تمایل می‌توانید این بخش را اجرا نکرده و در سلول های بعدی از مدل آموزش دیده‌ی پیشین استفاده کنید\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "aug = 'scale'\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"datasets/\"+ds_name, augmentation = aug)\n",
        "trainer.setTrainConfig(object_names_array=[\"fire\"], batch_size=8, num_experiments=10,\\\n",
        "                       augmentation = aug,\\\n",
        "                       train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.trainModel()\n",
        "!ls ./datasets/fire-dataset-outdoor-d2n_aug-scale/models/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.78\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  datasets/fire-dataset-outdoor-d2n_augscale/json/detection_config.json\n",
            "Evaluating over 60 samples taken from datasets/fire-dataset-outdoor-d2n/validation\n",
            "Training over 390 samples  given at datasets/fire-dataset-outdoor-d2n/train\n",
            "Training on: \t['fire']\n",
            "Training with Batch Size:  8\n",
            "Number of Training Samples:  390\n",
            "Number of Validation Samples:  60\n",
            "Number of Experiments:  10\n",
            "Training with transfer learning from pretrained Model\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "392/392 [==============================] - 264s 673ms/step - loss: 51.9999 - yolo_layer_9_loss: 8.7091 - yolo_layer_10_loss: 6.5080 - yolo_layer_11_loss: 25.2627 - val_loss: 36.1921 - val_yolo_layer_9_loss: 8.7303 - val_yolo_layer_10_loss: 1.8654 - val_yolo_layer_11_loss: 14.3594\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 2/10\n",
            "392/392 [==============================] - 282s 718ms/step - loss: 29.3493 - yolo_layer_9_loss: 5.5936 - yolo_layer_10_loss: 1.8688 - yolo_layer_11_loss: 11.0445 - val_loss: 31.9544 - val_yolo_layer_9_loss: 7.8124 - val_yolo_layer_10_loss: 1.5346 - val_yolo_layer_11_loss: 12.1856\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 3/10\n",
            "392/392 [==============================] - 279s 712ms/step - loss: 26.5626 - yolo_layer_9_loss: 4.6645 - yolo_layer_10_loss: 2.0906 - yolo_layer_11_loss: 9.7807 - val_loss: 33.2232 - val_yolo_layer_9_loss: 6.4064 - val_yolo_layer_10_loss: 0.7173 - val_yolo_layer_11_loss: 16.4376\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 4/10\n",
            "392/392 [==============================] - 287s 732ms/step - loss: 25.0496 - yolo_layer_9_loss: 4.5377 - yolo_layer_10_loss: 2.2440 - yolo_layer_11_loss: 8.9076 - val_loss: 27.9859 - val_yolo_layer_9_loss: 6.7482 - val_yolo_layer_10_loss: 1.1112 - val_yolo_layer_11_loss: 11.0610\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 5/10\n",
            "392/392 [==============================] - 283s 723ms/step - loss: 22.7311 - yolo_layer_9_loss: 3.9115 - yolo_layer_10_loss: 2.0552 - yolo_layer_11_loss: 7.9776 - val_loss: 27.9241 - val_yolo_layer_9_loss: 6.6183 - val_yolo_layer_10_loss: 1.1813 - val_yolo_layer_11_loss: 11.5893\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 6/10\n",
            "392/392 [==============================] - 290s 739ms/step - loss: 22.2824 - yolo_layer_9_loss: 4.0102 - yolo_layer_10_loss: 2.4420 - yolo_layer_11_loss: 7.5176 - val_loss: 25.7686 - val_yolo_layer_9_loss: 5.5386 - val_yolo_layer_10_loss: 1.2039 - val_yolo_layer_11_loss: 10.9148\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 7/10\n",
            "392/392 [==============================] - 275s 700ms/step - loss: 20.4175 - yolo_layer_9_loss: 3.6807 - yolo_layer_10_loss: 1.6978 - yolo_layer_11_loss: 7.1192 - val_loss: 25.9000 - val_yolo_layer_9_loss: 6.1800 - val_yolo_layer_10_loss: 1.0511 - val_yolo_layer_11_loss: 10.9478\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 8/10\n",
            "392/392 [==============================] - 294s 750ms/step - loss: 20.3755 - yolo_layer_9_loss: 3.8277 - yolo_layer_10_loss: 2.3737 - yolo_layer_11_loss: 6.6196 - val_loss: 26.7152 - val_yolo_layer_9_loss: 6.3079 - val_yolo_layer_10_loss: 2.3316 - val_yolo_layer_11_loss: 10.6787\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 9/10\n",
            "392/392 [==============================] - 278s 708ms/step - loss: 18.8845 - yolo_layer_9_loss: 3.4965 - yolo_layer_10_loss: 1.7689 - yolo_layer_11_loss: 6.3656 - val_loss: 26.2339 - val_yolo_layer_9_loss: 5.6819 - val_yolo_layer_10_loss: 0.9578 - val_yolo_layer_11_loss: 12.4811\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 10/10\n",
            "392/392 [==============================] - 279s 711ms/step - loss: 18.2778 - yolo_layer_9_loss: 3.3649 - yolo_layer_10_loss: 1.8508 - yolo_layer_11_loss: 6.1291 - val_loss: 25.3699 - val_yolo_layer_9_loss: 5.4552 - val_yolo_layer_10_loss: 1.6533 - val_yolo_layer_11_loss: 11.4661\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "ls: cannot access './datasets/fire-dataset-outdoor-d2n_augT/models/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaC3iO9R3Lej",
        "outputId": "d7a67f39-dfc8-421c-d56b-dc849138ac36"
      },
      "source": [
        "!ls datasets/fire-dataset-outdoor-d2n_augscale/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "detection_model-ex-001--loss-0052.000.h5\n",
            "detection_model-ex-002--loss-0029.349.h5\n",
            "detection_model-ex-003--loss-0026.563.h5\n",
            "detection_model-ex-004--loss-0025.050.h5\n",
            "detection_model-ex-005--loss-0022.731.h5\n",
            "detection_model-ex-006--loss-0022.282.h5\n",
            "detection_model-ex-007--loss-0020.418.h5\n",
            "detection_model-ex-008--loss-0020.376.h5\n",
            "detection_model-ex-009--loss-0018.884.h5\n",
            "detection_model-ex-010--loss-0018.278.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4vvGKosND_4",
        "outputId": "147a6263-384a-47e1-d898-b092ccff05a8"
      },
      "source": [
        "# !ls datasets/fire-dataset-outdoor-d2n_augscale/json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "detection_config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8spWuwM-_pV",
        "outputId": "e8dab758-ad56-4002-c64b-ae8e560bc719"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqhX-azz_Abf"
      },
      "source": [
        "# !cp datasets/fire-dataset-outdoor-d2n_augscale/models/detection_model-ex-010--loss-0018.278.h5 '/content/gdrive/My Drive/models/fire-10-epoch/outdoor-d2n/scale/'\n",
        "# !cp datasets/fire-dataset-outdoor-d2n_augscale/json/detection_config.json '/content/gdrive/My Drive/models/fire-10-epoch/outdoor-d2n/scale/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dTWcbjrMimT"
      },
      "source": [
        "# !cp datasets/fire-dataset-outdoor-d2n_augscale/json/detection_config.json '/content/gdrive/My Drive/models/fire-10-epoch/outdoor-d2n/scale/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnw3RZDH3Jkg",
        "outputId": "e266245a-b7e4-4702-f1bd-f55cb5ab6ee6"
      },
      "source": [
        "%%time\n",
        "# ارزیابی بهترین مدل بالا\n",
        "# ذکر شود model_path نام بهترین مدل بالا باید در \n",
        "\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"./datasets/\"+ds_name)\n",
        "metrics = trainer.evaluateModel(model_path=\"./datasets/\"+ds_name+\"_aug-scale/models/detection_model-ex-010--loss-0018.278.h5\",\\\n",
        "                                json_path=\"./datasets/\"+ds_name+\"_aug-scale/json/detection_config.json\",\\\n",
        "                                iou_threshold=0.2,\\\n",
        "                                object_threshold=0.3, nms_threshold=0.3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Model evaluation....\n",
            "Evaluating over 60 samples taken from ./datasets/fire-dataset-outdoor-d2n/validation\n",
            "Training over 390 samples  given at ./datasets/fire-dataset-outdoor-d2n/train\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model File:  ./datasets/fire-dataset-outdoor-d2n_augscale/models/detection_model-ex-010--loss-0018.278.h5 \n",
            "\n",
            "Evaluation samples:  60\n",
            "Using IoU:  0.2\n",
            "Using Object Threshold:  0.3\n",
            "Using Non-Maximum Suppression:  0.3\n",
            "fire: 0.7971\n",
            "mAP: 0.7971\n",
            "===============================\n",
            "CPU times: user 7.69 s, sys: 192 ms, total: 7.88 s\n",
            "Wall time: 7.83 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "6H9EGvqrQckH",
        "outputId": "5f23f92b-822f-4c9b-8eae-ad75a94a685b"
      },
      "source": [
        "# درصورتی که از مدل از قبل آموزش دیده استفاده کرده باشید،‌با دستورات زیر می‌توان مدل را روی تصاویر موجود در پوشه \n",
        "# path\n",
        "# اجرا کرد. \n",
        "# اگر از مدل آموزش دیده خود استفاده می‌کنید، نام مدل را باید اصلاح کنید.\n",
        "from PIL import Image\n",
        "import os, sys\n",
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "ds_name = \"fire-dataset-outdoor-d2n\"\n",
        "\n",
        "path = \"./datasets/\"+ds_name+\"/validation/images/\"\n",
        "dirs = os.listdir( path )\n",
        "# print(dirs)\n",
        "out_path = \"./results_\"+ds_name+\"_aug-scale\"\n",
        "os.mkdir(out_path)\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath(\"./datasets/\"+ds_name+\"_aug-scale/models/detection_model-ex-010--loss-0018.278.h5\")\n",
        "detector.setJsonPath(\"./datasets/\"+ds_name+\"_aug-scale/json/detection_config.json\")\n",
        "detector.loadModel()\n",
        "\n",
        "for item in dirs:\n",
        "    if os.path.isfile(path+item):\n",
        "        in_im = path+item\n",
        "        out_im = out_path+\"/\"+item\n",
        "        detections = detector.detectObjectsFromImage(input_image=in_im, output_image_path=out_im)\n",
        "\n",
        "# بعد از اجرای کد بالا، تصاویر در پوشه\n",
        "# results_fire-dataset-outdoor-d2n_aug-scale\n",
        "# قرار داده می‌شوند که می‌توان دانلود نمود\n",
        "!zip -r -q results_fire-dataset-outdoor-d2n_aug-scale.zip results_fire-dataset-outdoor-d2n_aug-scale/\n",
        "files.download('results_fire-dataset-outdoor-d2n_aug-scale.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_06c82e2e-559d-4fbb-abde-1779a0ac2c1f\", \"results_fire-dataset-outdoor-d2n_scale.zip\", 951093)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keJHhKS9UVRC",
        "outputId": "d19f1d0e-e277-463a-ad5d-36d50cbb87e0"
      },
      "source": [
        "if hasattr(time, 'tzset'):\n",
        "    os.environ['TZ'] = 'Asia/Tehran'\n",
        "    time.tzset()\n",
        "print(time.strftime('%X'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01:17:21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6PzEjuu3Lzb"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKalU4nQBZgF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6ed2f4-c872-4c05-cd5c-63354e487275"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug 21 22:42:38 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    24W /  75W |   7315MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVw3qwBLT5pn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}